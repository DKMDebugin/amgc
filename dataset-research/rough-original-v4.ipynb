{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import ipyparallel\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remote_imports():\n",
    "    import ast\n",
    "    from pandas.api.types import CategoricalDtype\n",
    "    import ipyparallel\n",
    "    import librosa\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import pywt\n",
    "    from scipy.stats import skew\n",
    "    \n",
    "def load(filepath):\n",
    "    \"\"\"\n",
    "    This method was adapted from the FMA: A Dataset For Music Analysis.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "\n",
    "    if 'features' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'echonest' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'genres' in filename:\n",
    "        return pd.read_csv(filepath, index_col=None)\n",
    "\n",
    "    if 'tracks' in filename:\n",
    "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "\n",
    "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
    "                   ('track', 'genres'), ('track', 'genres_all')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "                   ('album', 'date_created'), ('album', 'date_released'),\n",
    "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "                   ('artist', 'active_year_end')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "        SUBSETS = ('small', 'medium', 'large')\n",
    "        tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "\n",
    "        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
    "                   ('album', 'type'), ('album', 'information'),\n",
    "                   ('artist', 'bio')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].astype('category')\n",
    "\n",
    "        return tracks\n",
    "        \n",
    "def stats(feature):\n",
    "    return {\n",
    "        'mean': np.mean(feature), \n",
    "        'median': np.median(feature), \n",
    "        'std': np.std(feature), \n",
    "        'var': np.var(feature)\n",
    "    }\n",
    "\n",
    "def extra_stats(feature):\n",
    "    return {\n",
    "        'sb_energy': np.mean(np.abs(feature)),\n",
    "        'skewness': skew(feature)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MOUNTED_DATASET_PATH = '/home/macbookretina/s3-bucket'\n",
    "LOCAL_MOUNTED_DATASET_PATH = '/Users/macbookretina/Desktop/mount-s3-bucket'\n",
    "SAMPLE_FILE = '/Users/macbookretina/blues.00042.wav'\n",
    "GENRES = ['hiphop', 'rock', 'pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store for all features to be extracted except log-mel and mel-spectogram.\n",
    "dataframe = pd.DataFrame({\n",
    "    'genre_label': [],\n",
    "    'data_source': [],\n",
    "    \n",
    "    'mean_spec_centroid': [],\n",
    "    'median_spec_centroid': [],\n",
    "    'std_spec_centroid': [],\n",
    "    'var_spec_centroid': [],\n",
    "    \n",
    "    'mean_spec_rolloff': [],\n",
    "    'median_spec_rolloff': [],\n",
    "    'std_spec_rolloff': [],\n",
    "    'var_spec_rolloff': [],\n",
    "    \n",
    "    'mean_zcr': [],\n",
    "    'median_zcr': [],\n",
    "    'std_zcr': [],\n",
    "    'var_zcr': [],\n",
    "    \n",
    "    'mean_spec_bw': [],\n",
    "    'median_spec_bw': [],\n",
    "    'std_spec_bw': [],\n",
    "    'var_spec_bw': [],\n",
    "    \n",
    "    'mean_spec_contrast_1': [],\n",
    "    'median_spec_contrast_1': [],\n",
    "    'std_spec_contrast_1': [],\n",
    "    'var_spec_contrast_1': [],\n",
    "    \n",
    "    'mean_spec_contrast_2': [],\n",
    "    'median_spec_contrast_2': [],\n",
    "    'std_spec_contrast_2': [],\n",
    "    'var_spec_contrast_2': [],\n",
    "    \n",
    "    'mean_spec_contrast_3': [],\n",
    "    'median_spec_contrast_3': [],\n",
    "    'std_spec_contrast_3': [],\n",
    "    'var_spec_contrast_3': [],\n",
    "    \n",
    "    'mean_spec_contrast_4': [],\n",
    "    'median_spec_contrast_4': [],\n",
    "    'std_spec_contrast_4': [],\n",
    "    'var_spec_contrast_4': [],\n",
    "    \n",
    "    'mean_spec_contrast_5': [],\n",
    "    'median_spec_contrast_5': [],\n",
    "    'std_spec_contrast_5': [],\n",
    "    'var_spec_contrast_5': [],\n",
    "    \n",
    "    'mean_spec_contrast_6': [],\n",
    "    'median_spec_contrast_6': [],\n",
    "    'std_spec_contrast_6': [],\n",
    "    'var_spec_contrast_6': [],\n",
    "    \n",
    "    'mean_spec_contrast_7': [],\n",
    "    'median_spec_contrast_7': [],\n",
    "    'std_spec_contrast_7': [],\n",
    "    'var_spec_contrast_7': [],\n",
    "    \n",
    "    'mean_mfcc_1': [],\n",
    "    'median_mfcc_1': [],\n",
    "    'std_mfcc_1': [],\n",
    "    'var_mfcc_1': [],\n",
    "    \n",
    "    'mean_mfcc_2': [],\n",
    "    'median_mfcc_2': [],\n",
    "    'std_mfcc_2': [],\n",
    "    'var_mfcc_2': [],\n",
    "    \n",
    "    'mean_mfcc_3': [],\n",
    "    'median_mfcc_3': [],\n",
    "    'std_mfcc_3': [],\n",
    "    'var_mfcc_3': [],\n",
    "    \n",
    "    'mean_mfcc_4': [],\n",
    "    'median_mfcc_4': [],\n",
    "    'std_mfcc_4': [],\n",
    "    'var_mfcc_4': [],\n",
    "    \n",
    "    'mean_mfcc_5': [],\n",
    "    'median_mfcc_5': [],\n",
    "    'std_mfcc_5': [],\n",
    "    'var_mfcc_5': [],\n",
    "    \n",
    "    'mean_mfcc_6': [],\n",
    "    'median_mfcc_6': [],\n",
    "    'std_mfcc_6': [],\n",
    "    'var_mfcc_6': [],\n",
    "    \n",
    "    'mean_mfcc_7': [],\n",
    "    'median_mfcc_7': [],\n",
    "    'std_mfcc_7': [],\n",
    "    'var_mfcc_7': [],\n",
    "    \n",
    "    'mean_mfcc_8': [],\n",
    "    'median_mfcc_8': [],\n",
    "    'std_mfcc_8': [],\n",
    "    'var_mfcc_8': [],\n",
    "    \n",
    "    'mean_mfcc_9': [],\n",
    "    'median_mfcc_9': [],\n",
    "    'std_mfcc_9': [],\n",
    "    'var_mfcc_9': [],\n",
    "    \n",
    "    'mean_mfcc_10': [],\n",
    "    'median_mfcc_10': [],\n",
    "    'std_mfcc_10': [],\n",
    "    'var_mfcc_10': [],\n",
    "    \n",
    "    'mean_mfcc_11': [],\n",
    "    'median_mfcc_11': [],\n",
    "    'std_mfcc_11': [],\n",
    "    'var_mfcc_11': [],\n",
    "    \n",
    "    'mean_mfcc_12': [],\n",
    "    'median_mfcc_12': [],\n",
    "    'std_mfcc_12': [],\n",
    "    'var_mfcc_12': [],\n",
    "    \n",
    "    'mean_mfcc_13': [],\n",
    "    'median_mfcc_13': [],\n",
    "    'std_mfcc_13': [],\n",
    "    'var_mfcc_13': [],\n",
    "    \n",
    "    'lpc_1': [],\n",
    "    'lpc_2': [],\n",
    "    'lpc_3': [],\n",
    "    'lpc_4': [],\n",
    "    \n",
    "    'tempo': [],\n",
    "    \n",
    "    'mean_beats': [],\n",
    "    'median_beats': [],\n",
    "    'std_beats': [],\n",
    "    'var_beats': [],\n",
    "    \n",
    "    'mean_beats_timestamp': [],\n",
    "    'median_beats_timestamp': [],\n",
    "    'std_beats_timestamp': [],\n",
    "    'var_beats_timestamp': [],\n",
    "    \n",
    "    'mean_db4_cA4': [],\n",
    "    'median_db4_cA4': [],\n",
    "    'std_db4_cA4': [],\n",
    "    'var_db4_cA4': [],\n",
    "    'sb_energy_db4_cA4': [],\n",
    "    'skewness_db4_cA4': [],\n",
    "    \n",
    "    'mean_db4_cD4': [],\n",
    "    'median_db4_cD4': [],\n",
    "    'std_db4_cD4': [],\n",
    "    'var_db4_cD4': [],\n",
    "    'sb_energy_db4_cD4': [],\n",
    "    'skewness_db4_cD4': [],\n",
    "    \n",
    "    'mean_db4_cD3': [],\n",
    "    'median_db4_cD3': [],\n",
    "    'std_db4_cD3': [],\n",
    "    'var_db4_cD3': [],\n",
    "    'sb_energy_db4_cD3': [],\n",
    "    'skewness_db4_cD3': [],\n",
    "    \n",
    "    'mean_db4_cD2': [],\n",
    "    'median_db4_cD2': [],\n",
    "    'std_db4_cD2': [],\n",
    "    'var_db4_cD2': [],\n",
    "    'sb_energy_db4_cD2': [],\n",
    "    'skewness_db4_cD2': [],\n",
    "    \n",
    "    'mean_db4_cD1': [],\n",
    "    'median_db4_cD1': [],\n",
    "    'std_db4_cD1': [],\n",
    "    'var_db4_cD1': [],\n",
    "    'sb_energy_db4_cD1': [],\n",
    "    'skewness_db4_cD1': [],\n",
    "    \n",
    "    'mean_db5_cA4': [],\n",
    "    'median_db5_cA4': [],\n",
    "    'std_db5_cA4': [],\n",
    "    'var_db5_cA4': [],\n",
    "    'sb_energy_db5_cA4': [],\n",
    "    'skewness_db5_cA4': [],\n",
    "    \n",
    "    'mean_db5_cD4': [],\n",
    "    'median_db5_cD4': [],\n",
    "    'std_db5_cD4': [],\n",
    "    'var_db5_cD4': [],\n",
    "    'sb_energy_db5_cD4': [],\n",
    "    'skewness_db5_cD4': [],\n",
    "    \n",
    "    'mean_db5_cD3': [],\n",
    "    'median_db5_cD3': [],\n",
    "    'std_db5_cD3': [],\n",
    "    'var_db5_cD3': [],\n",
    "    'sb_energy_db5_cD3': [],\n",
    "    'skewness_db5_cD3': [],\n",
    "    \n",
    "    'mean_db5_cD2': [],\n",
    "    'median_db5_cD2': [],\n",
    "    'std_db5_cD2': [],\n",
    "    'var_db5_cD2': [],\n",
    "    'sb_energy_db5_cD2': [],\n",
    "    'skewness_db5_cD2': [],\n",
    "    \n",
    "    'mean_db5_cD1': [],\n",
    "    'median_db5_cD1': [],\n",
    "    'std_db5_cD1': [],\n",
    "    'var_db5_cD1': [],\n",
    "    'sb_energy_db5_cD1': [],\n",
    "    'skewness_db5_cD1': [],\n",
    "    \n",
    "    'mean_db8_cA7': [],\n",
    "    'median_db8_cA7': [],\n",
    "    'std_db8_cA7': [],\n",
    "    'var_db8_cA7': [],\n",
    "    'sb_energy_db8_cA7': [],\n",
    "    'skewness_db8_cA7': [],\n",
    "    \n",
    "    'mean_db8_cD7': [],\n",
    "    'median_db8_cD7': [],\n",
    "    'std_db8_cD7': [],\n",
    "    'var_db8_cD7': [],\n",
    "    'sb_energy_db8_cD7': [],\n",
    "    'skewness_db8_cD7': [],\n",
    "    \n",
    "    'mean_db8_cD6': [],\n",
    "    'median_db8_cD6': [],\n",
    "    'std_db8_cD6': [],\n",
    "    'var_db8_cD6': [],\n",
    "    'sb_energy_db8_cD6': [],\n",
    "    'skewness_db8_cD6': [],\n",
    "    \n",
    "    'mean_db8_cD5': [],\n",
    "    'median_db8_cD5': [],\n",
    "    'std_db8_cD5': [],\n",
    "    'var_db8_cD5': [],\n",
    "    'sb_energy_db8_cD5': [],\n",
    "    'skewness_db8_cD5': [],\n",
    "    \n",
    "    'mean_db8_cD4': [],\n",
    "    'median_db8_cD4': [],\n",
    "    'std_db8_cD4': [],\n",
    "    'var_db8_cD4': [],\n",
    "    'sb_energy_db8_cD4': [],\n",
    "    'skewness_db8_cD4': [],\n",
    "    \n",
    "    'mean_db8_cD3': [],\n",
    "    'median_db8_cD3': [],\n",
    "    'std_db8_cD3': [],\n",
    "    'var_db8_cD3': [],\n",
    "    'sb_energy_db8_cD3': [],\n",
    "    'skewness_db8_cD3': [],\n",
    "    \n",
    "    'mean_db8_cD2': [],\n",
    "    'median_db8_cD2': [],\n",
    "    'std_db8_cD2': [],\n",
    "    'var_db8_cD2': [],\n",
    "    'sb_energy_db8_cD2': [],\n",
    "    'skewness_db8_cD2': [],\n",
    "    \n",
    "    'mean_db8_cD1': [],\n",
    "    'median_db8_cD1': [],\n",
    "    'std_db8_cD1': [],\n",
    "    'var_db8_cD1': [],\n",
    "    'sb_energy_db8_cD1': [],\n",
    "    'skewness_db8_cD1': [],\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(dataframe, file, genre_label, data_source):\n",
    "    '''\n",
    "    This function takes a datafame, an audio file (check librosa for acceptable formats),\n",
    "    genre label, and datasource. It extract features from the audio and returns the dataframe with \n",
    "    the new row appended.\n",
    "    \n",
    "    Timbral, rhythmic, and wavelet features are extracted excluding log-mel and mel-spectogram.\n",
    "    \n",
    "    Parameters:\n",
    "    dataframe (pd.Dataframe): Dataframe to update with new row.\n",
    "    file (File or str): an audio file or file path.\n",
    "    genre_label (str): audio genre label\n",
    "    data_source (str): fma or gtzan\n",
    "    '''\n",
    "    # get sample rate of audio file\n",
    "    sample_rate = librosa.core.get_samplerate(file.path)\n",
    "\n",
    "    # load audio file as time series\n",
    "    time_series, _ = librosa.core.load(file.path, sample_rate)\n",
    "\n",
    "\n",
    "    # compute timbral features\n",
    "    # compute spectral centroid\n",
    "    spec_centroid = librosa.feature.spectral_centroid(time_series, sample_rate)\n",
    "    stats_spec_centroid = stats(spec_centroid)\n",
    "\n",
    "    # compute spectral roll-off\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(time_series, sample_rate)\n",
    "    stats_spec_rolloff = stats(spec_rolloff)\n",
    "\n",
    "    # compute zero crossing rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(time_series)\n",
    "    stats_zcr = stats(zcr)\n",
    "\n",
    "    # compute spectral bandwidth\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(time_series, sample_rate)\n",
    "    stats_spec_bw = stats(spec_bw[0])\n",
    "\n",
    "    # compute spectral contrast\n",
    "    spec_contrast = librosa.feature.spectral_contrast(time_series, sample_rate)\n",
    "    stats_spec_contrast_1 = stats(spec_contrast[0])\n",
    "    stats_spec_contrast_2 = stats(spec_contrast[1])\n",
    "    stats_spec_contrast_3 = stats(spec_contrast[2])\n",
    "    stats_spec_contrast_4 = stats(spec_contrast[3])\n",
    "    stats_spec_contrast_5 = stats(spec_contrast[4])\n",
    "    stats_spec_contrast_6 = stats(spec_contrast[5])\n",
    "    stats_spec_contrast_7 = stats(spec_contrast[6])\n",
    "\n",
    "    # compute 13 mel-frequency cepstral coefficients\n",
    "    mfcc = librosa.feature.mfcc(time_series, sample_rate, n_mfcc=13)\n",
    "    stat_mfcc_1 = stats(mfcc[0])\n",
    "    stat_mfcc_2 = stats(mfcc[1])\n",
    "    stat_mfcc_3 = stats(mfcc[2])\n",
    "    stat_mfcc_4 = stats(mfcc[3])\n",
    "    stat_mfcc_5 = stats(mfcc[4])\n",
    "    stat_mfcc_6 = stats(mfcc[5])\n",
    "    stat_mfcc_7 = stats(mfcc[6])\n",
    "    stat_mfcc_8 = stats(mfcc[7])\n",
    "    stat_mfcc_9 = stats(mfcc[8])\n",
    "    stat_mfcc_10 = stats(mfcc[9])\n",
    "    stat_mfcc_11 = stats(mfcc[10])\n",
    "    stat_mfcc_12 = stats(mfcc[11])\n",
    "    stat_mfcc_13 = stats(mfcc[12])\n",
    "\n",
    "    # compute 3rd order linear prediction coefficients\n",
    "    lpc = librosa.lpc(time_series, 3)\n",
    "\n",
    "\n",
    "    # compute rhythmic features\n",
    "    # compute tempo & beats\n",
    "    tempo, beats = librosa.beat.beat_track(time_series, sample_rate)\n",
    "    stats_beats = stats(beats)\n",
    "\n",
    "    # compute timestamps from beats\n",
    "    beats_timestamp = librosa.frames_to_time(beats, sample_rate)\n",
    "    stats_beats_timestamp = stats(beats_timestamp)\n",
    "\n",
    "\n",
    "    # compute wavelet features\n",
    "    # compute coefficients for Db4 at level 4 decomposition\n",
    "    db4_coeffs = pywt.wavedec(time_series, 'db4', level=4)\n",
    "    db4_cA4, db4_cD4, db4_cD3, db4_cD2, db4_cD1 = db4_coeffs\n",
    "    stats_db4_cA4 = {**stats(db4_cA4), **extra_stats(db4_cA4)}\n",
    "    stats_db4_cD4 = {**stats(db4_cD4), **extra_stats(db4_cD4)}\n",
    "    stats_db4_cD3 = {**stats(db4_cD3), **extra_stats(db4_cD3)}\n",
    "    stats_db4_cD2 = {**stats(db4_cD2), **extra_stats(db4_cD2)}\n",
    "    stats_db4_cD1 = {**stats(db4_cD1), **extra_stats(db4_cD1)}\n",
    "\n",
    "    # compute coefficients for Db5 at level 4 decomposition\n",
    "    db5_coeffs = pywt.wavedec(time_series, 'db5', level=4)\n",
    "    db5_cA4, db5_cD4, db5_cD3, db5_cD2, db5_cD1 = db5_coeffs\n",
    "    stats_db5_cA4 = {**stats(db5_cA4), **extra_stats(db5_cA4)}\n",
    "    stats_db5_cD4 = {**stats(db5_cD4), **extra_stats(db5_cD4)}\n",
    "    stats_db5_cD3 = {**stats(db5_cD3), **extra_stats(db5_cD3)}\n",
    "    stats_db5_cD2 = {**stats(db5_cD2), **extra_stats(db5_cD2)}\n",
    "    stats_db5_cD1 = {**stats(db5_cD1), **extra_stats(db5_cD1)}\n",
    "\n",
    "    # compute coefficients for Db8 at level 7 decomposition\n",
    "    db8_coeffs = pywt.wavedec(time_series, 'db4', level=7)\n",
    "    db8_cA7, db8_cD7, db8_cD6, db8_cD5, db8_cD4, db8_cD3, db8_cD2, db8_cD1 = db8_coeffs\n",
    "    stats_db8_cA7 = {**stats(db8_cA7), **extra_stats(db8_cA7)}\n",
    "    stats_db8_cD7 = {**stats(db8_cD7), **extra_stats(db8_cD7)}\n",
    "    stats_db8_cD6 = {**stats(db8_cD6), **extra_stats(db8_cD6)}\n",
    "    stats_db8_cD5 = {**stats(db8_cD5), **extra_stats(db8_cD5)}\n",
    "    stats_db8_cD4 = {**stats(db8_cD4), **extra_stats(db8_cD4)}\n",
    "    stats_db8_cD3 = {**stats(db8_cD3), **extra_stats(db8_cD3)}\n",
    "    stats_db8_cD2 = {**stats(db8_cD2), **extra_stats(db8_cD2)}\n",
    "    stats_db8_cD1 = {**stats(db8_cD1), **extra_stats(db8_cD1)}\n",
    "    \n",
    "    # create new row\n",
    "    new_row = {\n",
    "    'genre_label': genre_label,\n",
    "    'data_source': data_source,\n",
    "        \n",
    "    'mean_spec_centroid': stats_spec_centroid['mean'],\n",
    "    'median_spec_centroid': stats_spec_centroid['median'],\n",
    "    'std_spec_centroid': stats_spec_centroid['std'],\n",
    "    'var_spec_centroid': stats_spec_centroid['var'],\n",
    "    \n",
    "    'mean_spec_rolloff': stats_spec_rolloff['mean'],\n",
    "    'median_spec_rolloff': stats_spec_rolloff['median'],\n",
    "    'std_spec_rolloff': stats_spec_rolloff['std'],\n",
    "    'var_spec_rolloff': stats_spec_rolloff['var'],\n",
    "    \n",
    "    'mean_zcr': stats_zcr['mean'],\n",
    "    'median_zcr': stats_zcr['median'],\n",
    "    'std_zcr': stats_zcr['std'],\n",
    "    'var_zcr': stats_zcr['var'],\n",
    "    \n",
    "    'mean_spec_bw': stats_spec_bw['mean'],\n",
    "    'median_spec_bw': stats_spec_bw['median'],\n",
    "    'std_spec_bw': stats_spec_bw['std'],\n",
    "    'var_spec_bw': stats_spec_bw['var'],\n",
    "    \n",
    "    'mean_spec_contrast_1': stats_spec_contrast_1['mean'],\n",
    "    'median_spec_contrast_1': stats_spec_contrast_1['median'],\n",
    "    'std_spec_contrast_1': stats_spec_contrast_1['std'],\n",
    "    'var_spec_contrast_1': stats_spec_contrast_1['var'],\n",
    "    \n",
    "    'mean_spec_contrast_2': stats_spec_contrast_2['mean'],\n",
    "    'median_spec_contrast_2': stats_spec_contrast_2['median'],\n",
    "    'std_spec_contrast_2': stats_spec_contrast_2['std'],\n",
    "    'var_spec_contrast_2': stats_spec_contrast_2['var'],\n",
    "    \n",
    "    'mean_spec_contrast_3': stats_spec_contrast_3['mean'],\n",
    "    'median_spec_contrast_3': stats_spec_contrast_3['median'],\n",
    "    'std_spec_contrast_3': stats_spec_contrast_3['std'],\n",
    "    'var_spec_contrast_3': stats_spec_contrast_3['var'],\n",
    "    \n",
    "    'mean_spec_contrast_4': stats_spec_contrast_4['mean'],\n",
    "    'median_spec_contrast_4': stats_spec_contrast_4['median'],\n",
    "    'std_spec_contrast_4': stats_spec_contrast_4['std'],\n",
    "    'var_spec_contrast_4': stats_spec_contrast_4['var'],\n",
    "    \n",
    "    'mean_spec_contrast_5': stats_spec_contrast_5['mean'],\n",
    "    'median_spec_contrast_5': stats_spec_contrast_5['median'],\n",
    "    'std_spec_contrast_5': stats_spec_contrast_5['std'],\n",
    "    'var_spec_contrast_5': stats_spec_contrast_5['var'],\n",
    "    \n",
    "    'mean_spec_contrast_6': stats_spec_contrast_6['mean'],\n",
    "    'median_spec_contrast_6': stats_spec_contrast_6['median'],\n",
    "    'std_spec_contrast_6': stats_spec_contrast_6['std'],\n",
    "    'var_spec_contrast_6': stats_spec_contrast_6['var'],\n",
    "    \n",
    "    'mean_spec_contrast_7': stats_spec_contrast_7['mean'],\n",
    "    'median_spec_contrast_7': stats_spec_contrast_7['median'],\n",
    "    'std_spec_contrast_7': stats_spec_contrast_7['std'],\n",
    "    'var_spec_contrast_7': stats_spec_contrast_7['var'],\n",
    "    \n",
    "    'mean_mfcc_1': stat_mfcc_1['mean'],\n",
    "    'median_mfcc_1': stat_mfcc_1['median'],\n",
    "    'std_mfcc_1': stat_mfcc_1['std'],\n",
    "    'var_mfcc_1': stat_mfcc_1['var'],\n",
    "    \n",
    "    'mean_mfcc_2': stat_mfcc_2['mean'],\n",
    "    'median_mfcc_2': stat_mfcc_2['median'],\n",
    "    'std_mfcc_2': stat_mfcc_2['std'],\n",
    "    'var_mfcc_2': stat_mfcc_2['var'],\n",
    "    \n",
    "    'mean_mfcc_3': stat_mfcc_3['mean'],\n",
    "    'median_mfcc_3': stat_mfcc_3['median'],\n",
    "    'std_mfcc_3': stat_mfcc_3['std'],\n",
    "    'var_mfcc_3': stat_mfcc_3['var'],\n",
    "    \n",
    "    'mean_mfcc_4': stat_mfcc_4['mean'],\n",
    "    'median_mfcc_4': stat_mfcc_4['median'],\n",
    "    'std_mfcc_4': stat_mfcc_4['std'],\n",
    "    'var_mfcc_4': stat_mfcc_4['var'],\n",
    "    \n",
    "    'mean_mfcc_5': stat_mfcc_5['mean'],\n",
    "    'median_mfcc_5': stat_mfcc_5['median'],\n",
    "    'std_mfcc_5': stat_mfcc_5['std'],\n",
    "    'var_mfcc_5': stat_mfcc_5['var'],\n",
    "    \n",
    "    'mean_mfcc_6': stat_mfcc_6['mean'],\n",
    "    'median_mfcc_6': stat_mfcc_6['median'],\n",
    "    'std_mfcc_6': stat_mfcc_6['std'],\n",
    "    'var_mfcc_6': stat_mfcc_6['var'],\n",
    "    \n",
    "    'mean_mfcc_7': stat_mfcc_7['mean'],\n",
    "    'median_mfcc_7': stat_mfcc_7['median'],\n",
    "    'std_mfcc_7': stat_mfcc_7['std'],\n",
    "    'var_mfcc_7': stat_mfcc_7['var'],\n",
    "    \n",
    "    'mean_mfcc_8': stat_mfcc_8['mean'],\n",
    "    'median_mfcc_8': stat_mfcc_8['median'],\n",
    "    'std_mfcc_8': stat_mfcc_8['std'],\n",
    "    'var_mfcc_8':stat_mfcc_8['var'],\n",
    "    \n",
    "    'mean_mfcc_9': stat_mfcc_9['mean'],\n",
    "    'median_mfcc_9': stat_mfcc_9['median'],\n",
    "    'std_mfcc_9': stat_mfcc_9['std'],\n",
    "    'var_mfcc_9': stat_mfcc_9['var'],\n",
    "    \n",
    "    'mean_mfcc_10': stat_mfcc_10['mean'],\n",
    "    'median_mfcc_10': stat_mfcc_10['median'],\n",
    "    'std_mfcc_10': stat_mfcc_10['std'],\n",
    "    'var_mfcc_10': stat_mfcc_10['var'],\n",
    "    \n",
    "    'mean_mfcc_11': stat_mfcc_11['mean'],\n",
    "    'median_mfcc_11': stat_mfcc_11['median'],\n",
    "    'std_mfcc_11': stat_mfcc_11['std'],\n",
    "    'var_mfcc_11': stat_mfcc_11['var'],\n",
    "    \n",
    "    'mean_mfcc_12': stat_mfcc_12['mean'],\n",
    "    'median_mfcc_12': stat_mfcc_12['median'],\n",
    "    'std_mfcc_12': stat_mfcc_12['std'],\n",
    "    'var_mfcc_12': stat_mfcc_12['var'],\n",
    "    \n",
    "    'mean_mfcc_13': stat_mfcc_13['mean'],\n",
    "    'median_mfcc_13': stat_mfcc_13['median'],\n",
    "    'std_mfcc_13': stat_mfcc_13['std'],\n",
    "    'var_mfcc_13': stat_mfcc_13['var'],\n",
    "    \n",
    "    'lpc_1': lpc[0],\n",
    "    'lpc_2': lpc[1],\n",
    "    'lpc_3': lpc[2],\n",
    "    'lpc_4': lpc[3],\n",
    "    \n",
    "    'tempo': tempo,\n",
    "    \n",
    "    'mean_beats': stats_beats['mean'],\n",
    "    'median_beats': stats_beats['median'],\n",
    "    'std_beats': stats_beats['std'],\n",
    "    'var_beats': stats_beats['var'],\n",
    "    \n",
    "    'mean_beats_timestamp': stats_beats_timestamp['mean'],\n",
    "    'median_beats_timestamp': stats_beats_timestamp['median'],\n",
    "    'std_beats_timestamp': stats_beats_timestamp['std'],\n",
    "    'var_beats_timestamp': stats_beats_timestamp['var'],\n",
    "    \n",
    "    'mean_db4_cA4': stats_db4_cA4['mean'],\n",
    "    'median_db4_cA4': stats_db4_cA4['median'],\n",
    "    'std_db4_cA4': stats_db4_cA4['std'],\n",
    "    'var_db4_cA4': stats_db4_cA4['var'],\n",
    "    'sb_energy_db4_cA4': stats_db4_cA4['sb_energy'],\n",
    "    'skewness_db4_cA4': stats_db4_cA4['skewness'],\n",
    "    \n",
    "    'mean_db4_cD4': stats_db4_cD4['mean'],\n",
    "    'median_db4_cD4': stats_db4_cD4['median'],\n",
    "    'std_db4_cD4': stats_db4_cD4['std'],\n",
    "    'var_db4_cD4': stats_db4_cD4['var'],\n",
    "    'sb_energy_db4_cD4': stats_db4_cD4['sb_energy'],\n",
    "    'skewness_db4_cD4': stats_db4_cD4['skewness'],\n",
    "    \n",
    "    'mean_db4_cD3': stats_db4_cD3['mean'],\n",
    "    'median_db4_cD3': stats_db4_cD3['median'],\n",
    "    'std_db4_cD3': stats_db4_cD3['std'],\n",
    "    'var_db4_cD3': stats_db4_cD3['var'],\n",
    "    'sb_energy_db4_cD3': stats_db4_cD3['sb_energy'],\n",
    "    'skewness_db4_cD3': stats_db4_cD3['skewness'],\n",
    "    \n",
    "    'mean_db4_cD2': stats_db4_cD2['mean'],\n",
    "    'median_db4_cD2': stats_db4_cD2['median'],\n",
    "    'std_db4_cD2': stats_db4_cD2['std'],\n",
    "    'var_db4_cD2': stats_db4_cD2['var'],\n",
    "    'sb_energy_db4_cD2': stats_db4_cD2['sb_energy'],\n",
    "    'skewness_db4_cD2': stats_db4_cD2['skewness'],\n",
    "    \n",
    "    'mean_db4_cD1': stats_db4_cD1['mean'],\n",
    "    'median_db4_cD1': stats_db4_cD1['median'],\n",
    "    'std_db4_cD1': stats_db4_cD1['std'],\n",
    "    'var_db4_cD1': stats_db4_cD1['var'],\n",
    "    'sb_energy_db4_cD1': stats_db4_cD1['sb_energy'],\n",
    "    'skewness_db4_cD1': stats_db4_cD1['skewness'],\n",
    "    \n",
    "    'mean_db5_cA4': stats_db5_cA4['mean'],\n",
    "    'median_db5_cA4': stats_db5_cA4['median'],\n",
    "    'std_db5_cA4': stats_db5_cA4['std'],\n",
    "    'var_db5_cA4': stats_db5_cA4['var'],\n",
    "    'sb_energy_db5_cA4': stats_db5_cA4['sb_energy'],\n",
    "    'skewness_db5_cA4': stats_db5_cA4['skewness'],\n",
    "    \n",
    "    'mean_db5_cD4': stats_db5_cD4['mean'],\n",
    "    'median_db5_cD4': stats_db5_cD4['median'],\n",
    "    'std_db5_cD4': stats_db5_cD4['std'],\n",
    "    'var_db5_cD4': stats_db5_cD4['var'],\n",
    "    'sb_energy_db5_cD4': stats_db5_cD4['sb_energy'],\n",
    "    'skewness_db5_cD4': stats_db5_cD4['skewness'],\n",
    "    \n",
    "    'mean_db5_cD3': stats_db5_cD3['mean'],\n",
    "    'median_db5_cD3': stats_db5_cD3['median'],\n",
    "    'std_db5_cD3': stats_db5_cD3['std'],\n",
    "    'var_db5_cD3': stats_db5_cD3['var'],\n",
    "    'sb_energy_db5_cD3': stats_db5_cD3['sb_energy'],\n",
    "    'skewness_db5_cD3': stats_db5_cD3['skewness'],\n",
    "    \n",
    "    'mean_db5_cD2': stats_db5_cD2['mean'],\n",
    "    'median_db5_cD2': stats_db5_cD2['median'],\n",
    "    'std_db5_cD2': stats_db5_cD2['std'],\n",
    "    'var_db5_cD2': stats_db5_cD2['var'],\n",
    "    'sb_energy_db5_cD2': stats_db5_cD2['sb_energy'],\n",
    "    'skewness_db5_cD2': stats_db5_cD2['skewness'],\n",
    "    \n",
    "    'mean_db5_cD1': stats_db5_cD1['mean'],\n",
    "    'median_db5_cD1': stats_db5_cD1['median'],\n",
    "    'std_db5_cD1': stats_db5_cD1['std'],\n",
    "    'var_db5_cD1': stats_db5_cD1['var'],\n",
    "    'sb_energy_db5_cD1': stats_db5_cD1['sb_energy'],\n",
    "    'skewness_db5_cD1': stats_db5_cD1['skewness'],\n",
    "    \n",
    "    'mean_db8_cA7': stats_db8_cA7['mean'],\n",
    "    'median_db8_cA7': stats_db8_cA7['median'],\n",
    "    'std_db8_cA7': stats_db8_cA7['std'],\n",
    "    'var_db8_cA7': stats_db8_cA7['var'],\n",
    "    'sb_energy_db8_cA7': stats_db8_cA7['sb_energy'],\n",
    "    'skewness_db8_cA7': stats_db8_cA7['skewness'],\n",
    "    \n",
    "    'mean_db8_cD7': stats_db8_cD7['mean'],\n",
    "    'median_db8_cD7': stats_db8_cD7['median'],\n",
    "    'std_db8_cD7': stats_db8_cD7['std'],\n",
    "    'var_db8_cD7': stats_db8_cD7['var'],\n",
    "    'sb_energy_db8_cD7': stats_db8_cD7['sb_energy'],\n",
    "    'skewness_db8_cD7': stats_db8_cD7['skewness'],\n",
    "    \n",
    "    'mean_db8_cD6': stats_db8_cD6['mean'],\n",
    "    'median_db8_cD6': stats_db8_cD6['median'],\n",
    "    'std_db8_cD6': stats_db8_cD6['std'],\n",
    "    'var_db8_cD6': stats_db8_cD6['var'],\n",
    "    'sb_energy_db8_cD6': stats_db8_cD6['sb_energy'],\n",
    "    'skewness_db8_cD6': stats_db8_cD6['skewness'],\n",
    "    \n",
    "    'mean_db8_cD5': stats_db8_cD5['mean'],\n",
    "    'median_db8_cD5': stats_db8_cD5['median'],\n",
    "    'std_db8_cD5': stats_db8_cD5['std'],\n",
    "    'var_db8_cD5': stats_db8_cD5['var'],\n",
    "    'sb_energy_db8_cD5': stats_db8_cD5['sb_energy'],\n",
    "    'skewness_db8_cD5': stats_db8_cD5['skewness'],\n",
    "    \n",
    "    'mean_db8_cD4': stats_db8_cD4['mean'],\n",
    "    'median_db8_cD4': stats_db8_cD4['median'],\n",
    "    'std_db8_cD4': stats_db8_cD4['std'],\n",
    "    'var_db8_cD4': stats_db8_cD4['var'],\n",
    "    'sb_energy_db8_cD4': stats_db8_cD4['sb_energy'],\n",
    "    'skewness_db8_cD4': stats_db8_cD4['skewness'],\n",
    "    \n",
    "    'mean_db8_cD3': stats_db8_cD3['mean'],\n",
    "    'median_db8_cD3': stats_db8_cD3['median'],\n",
    "    'std_db8_cD3': stats_db8_cD3['std'],\n",
    "    'var_db8_cD3': stats_db8_cD3['var'],\n",
    "    'sb_energy_db8_cD3': stats_db8_cD3['sb_energy'],\n",
    "    'skewness_db8_cD3': stats_db8_cD3['skewness'],\n",
    "    \n",
    "    'mean_db8_cD2': stats_db8_cD2['mean'],\n",
    "    'median_db8_cD2': stats_db8_cD2['median'],\n",
    "    'std_db8_cD2': stats_db8_cD2['std'],\n",
    "    'var_db8_cD2': stats_db8_cD2['var'],\n",
    "    'sb_energy_db8_cD2': stats_db8_cD2['sb_energy'],\n",
    "    'skewness_db8_cD2': stats_db8_cD2['skewness'],\n",
    "    \n",
    "    'mean_db8_cD1': stats_db8_cD1['mean'],\n",
    "    'median_db8_cD1': stats_db8_cD1['median'],\n",
    "    'std_db8_cD1': stats_db8_cD1['std'],\n",
    "    'var_db8_cD1': stats_db8_cD1['var'],\n",
    "    'sb_energy_db8_cD1': stats_db8_cD1['sb_energy'],\n",
    "    'skewness_db8_cD1': stats_db8_cD1['skewness'],\n",
    "    }\n",
    "    \n",
    "    # append new row\n",
    "    dataframe = dataframe.append(new_row, ignore_index=True)\n",
    "    \n",
    "    print('appended features extracted from ' + str(file.name) + ' with genre: ' + genre_label )\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting track id and genres of tracks in the small subset of fma dataset\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# FMA\n",
    "# collect track id and genres of tracks in the small subset.\n",
    "\n",
    "print('collecting track id and genres of tracks in the small subset of fma dataset')\n",
    "\n",
    "tracks = load(MOUNTED_DATASET_PATH + '/fma_metadata/tracks.csv')\n",
    "fma_full = tracks[[('set', 'subset'), ('track', 'genre_top')]]\n",
    "small_subset = fma_full[('set', 'subset')] == 'small'\n",
    "fma_small = fma_full[small_subset]\n",
    "fma_small = pd.DataFrame({\n",
    "    'subset': fma_small[('set', 'subset')],\n",
    "    'label': fma_small[('track', 'genre_top')]\n",
    "})\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile: default\n",
      "IDs: [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# attach to a running cluster to notebook\n",
    "cluster = ipyparallel.Client()\n",
    "\n",
    "# Print profile name and process id numbers\n",
    "print('profile:', cluster.profile)\n",
    "print(\"IDs:\", cluster.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into tow set of 4 engines each and get DirectView object of each set.\n",
    "direct_views_first_4_engines = cluster[:4]\n",
    "direct_views_last_4_engines = cluster[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing ast on engine(s)\n",
      "importing CategoricalDtype from pandas.api.types on engine(s)\n",
      "importing ipyparallel on engine(s)\n",
      "importing librosa on engine(s)\n",
      "importing numpy on engine(s)\n",
      "importing os on engine(s)\n",
      "importing pandas on engine(s)\n",
      "importing pywt on engine(s)\n",
      "importing skew from scipy.stats on engine(s)\n",
      "importing ast on engine(s)\n",
      "importing CategoricalDtype from pandas.api.types on engine(s)\n",
      "importing ipyparallel on engine(s)\n",
      "importing librosa on engine(s)\n",
      "importing numpy on engine(s)\n",
      "importing os on engine(s)\n",
      "importing pandas on engine(s)\n",
      "importing pywt on engine(s)\n",
      "importing skew from scipy.stats on engine(s)\n"
     ]
    }
   ],
   "source": [
    "# sync import for each DirectView object\n",
    "with direct_views_first_4_engines.sync_imports():\n",
    "    remote_imports()\n",
    "    \n",
    "with direct_views_last_4_engines.sync_imports():\n",
    "    remote_imports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: _push>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize shared resouces for each DirectView object\n",
    "direct_views_first_4_engines.push({\n",
    "    'MOUNTED_DATASET_PATH': MOUNTED_DATASET_PATH,\n",
    "    'LOCAL_MOUNTED_DATASET_PATH': LOCAL_MOUNTED_DATASET_PATH,\n",
    "    'SAMPLE_FILE': SAMPLE_FILE,\n",
    "    'GENRES': GENRES,\n",
    "    'extract_audio_features': extract_audio_features,\n",
    "    'dataframe': dataframe,\n",
    "    'fma_small': fma_small,\n",
    "})\n",
    "\n",
    "direct_views_last_4_engines.push({\n",
    "    'MOUNTED_DATASET_PATH': MOUNTED_DATASET_PATH,\n",
    "    'LOCAL_MOUNTED_DATASET_PATH': LOCAL_MOUNTED_DATASET_PATH,\n",
    "    'SAMPLE_FILE': SAMPLE_FILE,\n",
    "    'GENRES': GENRES,\n",
    "    'extract_audio_features': extract_audio_features,\n",
    "    'dataframe': dataframe,\n",
    "    'fma_small': fma_small,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate DirectView object and set suffix\n",
    "direct_views_first_4_engines.activate('_first')\n",
    "direct_views_last_4_engines.activate('_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTZAN\n",
    "# extract features\n",
    "\n",
    "print('extracting features from gtzan dataset')\n",
    "\n",
    "for file in os.scandir(MOUNTED_DATASET_PATH + '/gtzan/wavfiles'):\n",
    "    if file.is_file():\n",
    "        genre_label = str(file.name).split('.')[0]\n",
    "        if genre_label in GENRES:\n",
    "            dataframe = extract_audio_features(dataframe, file, genre_label, 'gtzan')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FMA\n",
    "# extract features\n",
    "\n",
    "print('extracting features from fma dataset')\n",
    "\n",
    "for directory in os.scandir(MOUNTED_DATASET_PATH + '/fma_small'):\n",
    "    if directory.is_dir():\n",
    "        for file in os.scandir(directory.path):\n",
    "            if file.is_file():\n",
    "                track_id = int(file.name[:-4].lstrip('0'))\n",
    "                # map track id to genre label\n",
    "                genre_label = fma_small.at[track_id, 'label'].lower().replace('-', '')\n",
    "                if genre_label in GENRES:\n",
    "                    dataframe = extract_audio_features(dataframe, file, genre_label, 'fma')\n",
    "\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting log-mel from gtzan dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macbookretina/.local/lib/python3.5/site-packages/librosa/core/spectrum.py:1702: UserWarning: amplitude_to_db was called on complex input so phase information will be discarded. To suppress this warning, call amplitude_to_db(np.abs(S)) instead.\n",
      "  warnings.warn('amplitude_to_db was called on complex input so phase '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sizes of all the log-mel in our data set are equal: False\n",
      "The maximum size is: (84, 1320)\n"
     ]
    }
   ],
   "source": [
    "# check size of  log-mel / constant-Q transform in gtzan\n",
    "\n",
    "# creating an empty list to store sizes in\n",
    "sizes_1 = []\n",
    "\n",
    "print('extracting log-mel from gtzan dataset')\n",
    "\n",
    "for file in os.scandir(MOUNTED_DATASET_PATH + '/gtzan/wavfiles'):\n",
    "    if file.is_file():\n",
    "        \n",
    "        # extract genre label\n",
    "        genre_label = str(file.name).split('.')[0]\n",
    "        \n",
    "        if genre_label in GENRES:\n",
    "            \n",
    "            # get sample rate of audio file\n",
    "            sample_rate = librosa.core.get_samplerate(file.path)\n",
    "\n",
    "            # load audio file as time series\n",
    "            time_series, _ = librosa.core.load(file.path, sample_rate)\n",
    "\n",
    "            # compute cqt\n",
    "            cqt = librosa.cqt(time_series, sample_rate)\n",
    "\n",
    "            # convert from amplitude to decibels unit\n",
    "            scaled_cqt = librosa.amplitude_to_db(cqt, ref=np.max) \n",
    "\n",
    "            # adding the size to the list\n",
    "            sizes.append(scaled_cqt.shape)\n",
    "\n",
    "# check if all sizes are the same\n",
    "print('The sizes of all the log-mel in our data set are equal: ' +  str(len(set(sizes)) == 1))\n",
    "\n",
    "# check the max size\n",
    "print('The maximum size is: ' + str(max(sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting mel-spectogram from gtzan dataset\n",
      "The sizes of all the log-mel in our data set are equal: False\n",
      "The maximum size is: (128, 1320)\n"
     ]
    }
   ],
   "source": [
    "# check size of mel-spectogram in gtzan\n",
    "\n",
    "# creating an empty list to store sizes in\n",
    "sizes_2 = []\n",
    "\n",
    "print('extracting mel-spectogram from gtzan dataset')\n",
    "\n",
    "for file in os.scandir(MOUNTED_DATASET_PATH + '/gtzan/wavfiles'):\n",
    "    if file.is_file():\n",
    "        \n",
    "        # extract genre label\n",
    "        genre_label = str(file.name).split('.')[0]\n",
    "        \n",
    "        if genre_label in GENRES:\n",
    "            \n",
    "            # get sample rate of audio file\n",
    "            sample_rate = librosa.core.get_samplerate(file.path)\n",
    "\n",
    "            # load audio file as time series\n",
    "            time_series, _ = librosa.core.load(file.path, sample_rate)\n",
    "\n",
    "            # compute spectogram\n",
    "            mel_spect = librosa.feature.melspectrogram(time_series, sample_rate)\n",
    "\n",
    "            # convert spectogram to decibels unit \n",
    "            scaled_mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "\n",
    "            # adding the size to the list\n",
    "            sizes.append(scaled_mel_spect.shape)\n",
    "    \n",
    "# check if all sizes are the same\n",
    "print('The sizes of all the log-mel in our data set are equal: ' +  str(len(set(sizes)) == 1))\n",
    "\n",
    "# check the max size\n",
    "print('The maximum size is: ' + str(max(sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px_first --targets 0 --noblock\n",
    "# check size of  log-mel / constant-Q transform in fma\n",
    "    \n",
    "# creating an empty list to store sizes in\n",
    "sizes = []\n",
    "\n",
    "print('extracting log-mel from fma dataset')\n",
    "\n",
    "for directory in os.scandir(MOUNTED_DATASET_PATH + '/fma_small'):\n",
    "    if directory.is_dir():\n",
    "        for file in os.scandir(directory.path):\n",
    "            if file.is_file():\n",
    "\n",
    "                # extract track id\n",
    "                track_id = int(file.name[:-4].lstrip('0'))\n",
    "\n",
    "                # map track id to genre label\n",
    "                genre_label = fma_small.at[track_id, 'label'].lower().replace('-', '')\n",
    "\n",
    "                if genre_label in GENRES:\n",
    "\n",
    "                    # get sample rate of audio file\n",
    "                    sample_rate = librosa.core.get_samplerate(str(file.path))\n",
    "\n",
    "                    # load audio file as time series\n",
    "                    time_series, _ = librosa.core.load(file.path, sample_rate)\n",
    "\n",
    "                    # compute cqt\n",
    "                    cqt = librosa.cqt(time_series, sample_rate)\n",
    "\n",
    "                    # convert from amplitude to decibels unit\n",
    "                    scaled_cqt = librosa.amplitude_to_db(cqt, ref=numpy.max) \n",
    "\n",
    "                    # adding the size to the list\n",
    "                    sizes.append(scaled_cqt.shape)\n",
    "\n",
    "# check if all sizes are the same\n",
    "print('The sizes of all the log-mel in our data set are equal: ' +  str(len(set(sizes)) == 1))\n",
    "\n",
    "# check the max size\n",
    "print('The maximum size is: ' + str(max(sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px_last --targets 4 --noblock\n",
    "# check size of  mel-spectogram  in fma\n",
    "\n",
    "# creating an empty list to store sizes in\n",
    "sizes = []\n",
    "\n",
    "print('extracting mel-spectogram  from fma dataset')\n",
    "\n",
    "for directory in os.scandir(MOUNTED_DATASET_PATH + '/fma_small'):\n",
    "    if directory.is_dir():\n",
    "        for file in os.scandir(directory.path):\n",
    "            if file.is_file():\n",
    "\n",
    "                # extract track id\n",
    "                track_id = int(file.name[:-4].lstrip('0'))\n",
    "\n",
    "                # map track id to genre label\n",
    "                genre_label = fma_small.at[track_id, 'label'].lower().replace('-', '')\n",
    "\n",
    "                if genre_label in GENRES:\n",
    "\n",
    "                    # get sample rate of audio file\n",
    "                    sample_rate = librosa.core.get_samplerate(file.path)\n",
    "\n",
    "                    # load audio file as time series\n",
    "                    time_series, _ = librosa.core.load(file.path, sample_rate)\n",
    "\n",
    "                    # compute spectogram\n",
    "                    mel_spect = librosa.feature.melspectrogram(time_series, sample_rate)\n",
    "\n",
    "                    # convert spectogram to decibels unit \n",
    "                    scaled_mel_spect = librosa.power_to_db(mel_spect, ref=numpy.max)\n",
    "\n",
    "                    # adding the size to the list\n",
    "                    sizes.append(scaled_mel_spect.shape)                \n",
    "\n",
    "# check if all sizes are the same\n",
    "print('The sizes of all the log-mel in our data set are equal: ' +  str(len(set(sizes)) == 1))\n",
    "\n",
    "# check the max size\n",
    "print('The maximum size is: ' + str(max(sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pxresult_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pxresult_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract log-mel / constant-Q transform in gtzan\n",
    "\n",
    "# create an empty list to store extract feature and label\n",
    "cqts = []\n",
    "genre_labels_1 = []\n",
    "\n",
    "print('extracting log-mel from gtzan dataset')\n",
    "\n",
    "for file in os.scandir(MOUNTED_DATASET_PATH + '/gtzan/wavfiles'):\n",
    "    if file.is_file():\n",
    "        # extract genre label and append to list\n",
    "        genre_label = str(file.name).split('.')[0]\n",
    "        genre_labels_1.append(genre_label)\n",
    "        \n",
    "        if genre_label in GENRES:\n",
    "        \n",
    "            # get sample rate of audio file\n",
    "            sample_rate = librosa.core.get_samplerate(file.path)\n",
    "\n",
    "            # load audio file as time series\n",
    "            time_series, _ = librosa.core.load(file.path, sample_rate)\n",
    "\n",
    "            # compute cqt\n",
    "            cqt = librosa.cqt(time_series, sample_rate)\n",
    "\n",
    "            # convert from amplitude to decibels unit\n",
    "            scaled_cqt = librosa.amplitude_to_db(cqt, ref=np.max) \n",
    "\n",
    "            # adjust the size to (84, 1320) as it is the max size\n",
    "            if scaled_cqt.shape[1] != 1320:\n",
    "                scaled_cqt.resize(84, 1320, refcheck=False)\n",
    "\n",
    "            # flatten to fit into dataframe and add to the list\n",
    "            scaled_cqt = scaled_cqt.flatten()\n",
    "            cqts.append(scaled_cqt)\n",
    "        \n",
    "# convert the lists to arrays so it can be stacked\n",
    "cqts = np.array(cqts)\n",
    "genre_labels = np.array(genre_labels).reshape(1000, 1)\n",
    "\n",
    "# create dataframe\n",
    "cqt_df = pd.DataFrame(np.hstack((genre_labels, cqts)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract mel-spectogram in gtzan\n",
    "\n",
    "# create an empty list to store extract feature and label\n",
    "mel_spects = []\n",
    "genre_labels_2 = []\n",
    "\n",
    "print('extracting mel-spectogram from gtzan dataset')\n",
    "\n",
    "for file in os.scandir(MOUNTED_DATASET_PATH + '/gtzan/wavfiles'):\n",
    "    if file.is_file():\n",
    "        # extract genre label and append to list\n",
    "        genre_label = str(file.name).split('.')[0]\n",
    "        genre_labels_2.append(genre_label)\n",
    "        \n",
    "        if genre_label in GENRES:\n",
    "        \n",
    "            # get sample rate of audio file\n",
    "            sample_rate = librosa.core.get_samplerate(file.path)\n",
    "\n",
    "            # load audio file as time series\n",
    "            time_series, _ = librosa.core.load(file.path, sample_rate)\n",
    "\n",
    "            # compute spectogram\n",
    "            mel_spect = librosa.feature.melspectrogram(time_series, sample_rate)\n",
    "\n",
    "            # convert spectogram to decibels unit \n",
    "            scaled_mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "\n",
    "            # adjust the size to (128, 1320) as it is the max size\n",
    "            if scaled_mel_spect.shape[1] != 1320:\n",
    "                scaled_mel_spect.resize(128, 1320, refcheck=False)\n",
    "\n",
    "            # flatten to fit into dataframe and add to the list\n",
    "            scaled_mel_spect = scaled_mel_spect.flatten()\n",
    "            mel_spects.append(scaled_mel_spect)\n",
    "        \n",
    "# convert the lists to arrays so it can be stacked\n",
    "mel_spects = np.array(mel_spects)\n",
    "genre_labels = np.array(genre_labels).reshape(1000, 1)\n",
    "\n",
    "# create dataframe\n",
    "mel_spect_df = pd.DataFrame(np.hstack((genre_labels, mel_spects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px_first --targets 0 --noblock\n",
    "print('start 1')\n",
    "import time\n",
    "time.sleep(10)\n",
    "print(time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1\n",
      "time.struct_time(tm_year=2020, tm_mon=5, tm_mday=25, tm_hour=16, tm_min=29, tm_sec=16, tm_wday=0, tm_yday=146, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "%pxresult_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px_last --targets 4 --noblock\n",
    "print('start 2')\n",
    "import time\n",
    "time.sleep(6)\n",
    "print(time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2\n",
      "time.struct_time(tm_year=2020, tm_mon=5, tm_mday=25, tm_hour=16, tm_min=29, tm_sec=14, tm_wday=0, tm_yday=146, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "%pxresult_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%px_ %connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
