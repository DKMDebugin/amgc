{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "from tensorflow.keras import callbacks\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "import pandas\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import seaborn\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "WORKING_DIR_PATH = globals()['_dh'][0]\n",
    "WORKING_DIR_PARENT_PATH = os.path.dirname(WORKING_DIR_PATH)\n",
    "sys.path.insert(1, WORKING_DIR_PARENT_PATH)\n",
    "from custom_module.utilities import (\n",
    "    GENRES,\n",
    "    MOUNTED_DATASET_PATH,\n",
    "    normalization_pipeline,\n",
    "    set_shape_create_cnn_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25th_percentile_db4_cA4</th>\n",
       "      <th>25th_percentile_db4_cD1</th>\n",
       "      <th>25th_percentile_db4_cD2</th>\n",
       "      <th>25th_percentile_db4_cD3</th>\n",
       "      <th>25th_percentile_db4_cD4</th>\n",
       "      <th>25th_percentile_db5_cA4</th>\n",
       "      <th>25th_percentile_db5_cD1</th>\n",
       "      <th>25th_percentile_db5_cD2</th>\n",
       "      <th>25th_percentile_db5_cD3</th>\n",
       "      <th>25th_percentile_db5_cD4</th>\n",
       "      <th>...</th>\n",
       "      <th>zcr_db5_cD3</th>\n",
       "      <th>zcr_db5_cD4</th>\n",
       "      <th>zcr_db8_cA7</th>\n",
       "      <th>zcr_db8_cD1</th>\n",
       "      <th>zcr_db8_cD2</th>\n",
       "      <th>zcr_db8_cD3</th>\n",
       "      <th>zcr_db8_cD4</th>\n",
       "      <th>zcr_db8_cD5</th>\n",
       "      <th>zcr_db8_cD6</th>\n",
       "      <th>zcr_db8_cD7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236240</td>\n",
       "      <td>-0.012063</td>\n",
       "      <td>-0.027807</td>\n",
       "      <td>-0.051443</td>\n",
       "      <td>-0.082820</td>\n",
       "      <td>-0.237137</td>\n",
       "      <td>-0.011746</td>\n",
       "      <td>-0.027222</td>\n",
       "      <td>-0.051066</td>\n",
       "      <td>-0.082349</td>\n",
       "      <td>...</td>\n",
       "      <td>48729.0</td>\n",
       "      <td>24515.0</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>236539.0</td>\n",
       "      <td>100477.0</td>\n",
       "      <td>48721.0</td>\n",
       "      <td>24523.0</td>\n",
       "      <td>10601.0</td>\n",
       "      <td>5868.0</td>\n",
       "      <td>2136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.733787</td>\n",
       "      <td>-0.017003</td>\n",
       "      <td>-0.045150</td>\n",
       "      <td>-0.053358</td>\n",
       "      <td>-0.045559</td>\n",
       "      <td>-0.728479</td>\n",
       "      <td>-0.016115</td>\n",
       "      <td>-0.044458</td>\n",
       "      <td>-0.053728</td>\n",
       "      <td>-0.045010</td>\n",
       "      <td>...</td>\n",
       "      <td>40467.0</td>\n",
       "      <td>21751.0</td>\n",
       "      <td>4280.0</td>\n",
       "      <td>232788.0</td>\n",
       "      <td>104560.0</td>\n",
       "      <td>40835.0</td>\n",
       "      <td>21922.0</td>\n",
       "      <td>11688.0</td>\n",
       "      <td>5678.0</td>\n",
       "      <td>4187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.206548</td>\n",
       "      <td>-0.001990</td>\n",
       "      <td>-0.004977</td>\n",
       "      <td>-0.010344</td>\n",
       "      <td>-0.032882</td>\n",
       "      <td>-0.206663</td>\n",
       "      <td>-0.001933</td>\n",
       "      <td>-0.004869</td>\n",
       "      <td>-0.009837</td>\n",
       "      <td>-0.031671</td>\n",
       "      <td>...</td>\n",
       "      <td>51110.0</td>\n",
       "      <td>28460.0</td>\n",
       "      <td>3429.0</td>\n",
       "      <td>238953.0</td>\n",
       "      <td>98627.0</td>\n",
       "      <td>50426.0</td>\n",
       "      <td>28197.0</td>\n",
       "      <td>12380.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>2853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.505051</td>\n",
       "      <td>-0.017088</td>\n",
       "      <td>-0.050502</td>\n",
       "      <td>-0.085439</td>\n",
       "      <td>-0.155965</td>\n",
       "      <td>-0.503971</td>\n",
       "      <td>-0.016430</td>\n",
       "      <td>-0.050478</td>\n",
       "      <td>-0.080363</td>\n",
       "      <td>-0.153229</td>\n",
       "      <td>...</td>\n",
       "      <td>46009.0</td>\n",
       "      <td>24784.0</td>\n",
       "      <td>4084.0</td>\n",
       "      <td>239878.0</td>\n",
       "      <td>106315.0</td>\n",
       "      <td>46383.0</td>\n",
       "      <td>25001.0</td>\n",
       "      <td>10550.0</td>\n",
       "      <td>6405.0</td>\n",
       "      <td>3401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.265025</td>\n",
       "      <td>-0.007068</td>\n",
       "      <td>-0.017015</td>\n",
       "      <td>-0.033292</td>\n",
       "      <td>-0.048008</td>\n",
       "      <td>-0.263057</td>\n",
       "      <td>-0.006823</td>\n",
       "      <td>-0.016241</td>\n",
       "      <td>-0.032975</td>\n",
       "      <td>-0.046946</td>\n",
       "      <td>...</td>\n",
       "      <td>50126.0</td>\n",
       "      <td>21473.0</td>\n",
       "      <td>3355.0</td>\n",
       "      <td>235508.0</td>\n",
       "      <td>96446.0</td>\n",
       "      <td>50054.0</td>\n",
       "      <td>21542.0</td>\n",
       "      <td>11100.0</td>\n",
       "      <td>6028.0</td>\n",
       "      <td>3176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>-0.104572</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>-0.018606</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.001230</td>\n",
       "      <td>-0.004309</td>\n",
       "      <td>-0.018012</td>\n",
       "      <td>...</td>\n",
       "      <td>111718.0</td>\n",
       "      <td>57071.0</td>\n",
       "      <td>5266.0</td>\n",
       "      <td>478728.0</td>\n",
       "      <td>194404.0</td>\n",
       "      <td>110085.0</td>\n",
       "      <td>56729.0</td>\n",
       "      <td>26120.0</td>\n",
       "      <td>10705.0</td>\n",
       "      <td>4714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>-0.064313</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>-0.004044</td>\n",
       "      <td>-0.013585</td>\n",
       "      <td>-0.064493</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.003693</td>\n",
       "      <td>-0.013236</td>\n",
       "      <td>...</td>\n",
       "      <td>100899.0</td>\n",
       "      <td>57721.0</td>\n",
       "      <td>5961.0</td>\n",
       "      <td>378640.0</td>\n",
       "      <td>180357.0</td>\n",
       "      <td>98690.0</td>\n",
       "      <td>57296.0</td>\n",
       "      <td>25947.0</td>\n",
       "      <td>13375.0</td>\n",
       "      <td>3125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>-0.477425</td>\n",
       "      <td>-0.000967</td>\n",
       "      <td>-0.004003</td>\n",
       "      <td>-0.008481</td>\n",
       "      <td>-0.038837</td>\n",
       "      <td>-0.476932</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>-0.004009</td>\n",
       "      <td>-0.007479</td>\n",
       "      <td>-0.036333</td>\n",
       "      <td>...</td>\n",
       "      <td>95367.0</td>\n",
       "      <td>62597.0</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>491052.0</td>\n",
       "      <td>210852.0</td>\n",
       "      <td>92628.0</td>\n",
       "      <td>61759.0</td>\n",
       "      <td>24119.0</td>\n",
       "      <td>12008.0</td>\n",
       "      <td>6321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>-0.328624</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>-0.008336</td>\n",
       "      <td>-0.021885</td>\n",
       "      <td>-0.049970</td>\n",
       "      <td>-0.329515</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>-0.008131</td>\n",
       "      <td>-0.021180</td>\n",
       "      <td>-0.048207</td>\n",
       "      <td>...</td>\n",
       "      <td>101933.0</td>\n",
       "      <td>50380.0</td>\n",
       "      <td>5290.0</td>\n",
       "      <td>483699.0</td>\n",
       "      <td>219884.0</td>\n",
       "      <td>100631.0</td>\n",
       "      <td>49950.0</td>\n",
       "      <td>30214.0</td>\n",
       "      <td>9810.0</td>\n",
       "      <td>5397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>-0.794837</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>-0.001355</td>\n",
       "      <td>-0.016222</td>\n",
       "      <td>-0.792587</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.012002</td>\n",
       "      <td>...</td>\n",
       "      <td>83010.0</td>\n",
       "      <td>50099.0</td>\n",
       "      <td>2977.0</td>\n",
       "      <td>314037.0</td>\n",
       "      <td>172281.0</td>\n",
       "      <td>68302.0</td>\n",
       "      <td>46699.0</td>\n",
       "      <td>30988.0</td>\n",
       "      <td>13057.0</td>\n",
       "      <td>4685.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3337 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      25th_percentile_db4_cA4  25th_percentile_db4_cD1  \\\n",
       "0                   -0.236240                -0.012063   \n",
       "1                   -0.733787                -0.017003   \n",
       "2                   -0.206548                -0.001990   \n",
       "3                   -0.505051                -0.017088   \n",
       "4                   -0.265025                -0.007068   \n",
       "...                       ...                      ...   \n",
       "3332                -0.104572                -0.000267   \n",
       "3333                -0.064313                -0.000214   \n",
       "3334                -0.477425                -0.000967   \n",
       "3335                -0.328624                -0.001875   \n",
       "3336                -0.794837                -0.000132   \n",
       "\n",
       "      25th_percentile_db4_cD2  25th_percentile_db4_cD3  \\\n",
       "0                   -0.027807                -0.051443   \n",
       "1                   -0.045150                -0.053358   \n",
       "2                   -0.004977                -0.010344   \n",
       "3                   -0.050502                -0.085439   \n",
       "4                   -0.017015                -0.033292   \n",
       "...                       ...                      ...   \n",
       "3332                -0.001287                -0.004655   \n",
       "3333                -0.000820                -0.004044   \n",
       "3334                -0.004003                -0.008481   \n",
       "3335                -0.008336                -0.021885   \n",
       "3336                -0.000183                -0.001355   \n",
       "\n",
       "      25th_percentile_db4_cD4  25th_percentile_db5_cA4  \\\n",
       "0                   -0.082820                -0.237137   \n",
       "1                   -0.045559                -0.728479   \n",
       "2                   -0.032882                -0.206663   \n",
       "3                   -0.155965                -0.503971   \n",
       "4                   -0.048008                -0.263057   \n",
       "...                       ...                      ...   \n",
       "3332                -0.018606                -0.104197   \n",
       "3333                -0.013585                -0.064493   \n",
       "3334                -0.038837                -0.476932   \n",
       "3335                -0.049970                -0.329515   \n",
       "3336                -0.016222                -0.792587   \n",
       "\n",
       "      25th_percentile_db5_cD1  25th_percentile_db5_cD2  \\\n",
       "0                   -0.011746                -0.027222   \n",
       "1                   -0.016115                -0.044458   \n",
       "2                   -0.001933                -0.004869   \n",
       "3                   -0.016430                -0.050478   \n",
       "4                   -0.006823                -0.016241   \n",
       "...                       ...                      ...   \n",
       "3332                -0.000241                -0.001230   \n",
       "3333                -0.000202                -0.000685   \n",
       "3334                -0.000873                -0.004009   \n",
       "3335                -0.001693                -0.008131   \n",
       "3336                -0.000132                -0.000146   \n",
       "\n",
       "      25th_percentile_db5_cD3  25th_percentile_db5_cD4  ...  zcr_db5_cD3  \\\n",
       "0                   -0.051066                -0.082349  ...      48729.0   \n",
       "1                   -0.053728                -0.045010  ...      40467.0   \n",
       "2                   -0.009837                -0.031671  ...      51110.0   \n",
       "3                   -0.080363                -0.153229  ...      46009.0   \n",
       "4                   -0.032975                -0.046946  ...      50126.0   \n",
       "...                       ...                      ...  ...          ...   \n",
       "3332                -0.004309                -0.018012  ...     111718.0   \n",
       "3333                -0.003693                -0.013236  ...     100899.0   \n",
       "3334                -0.007479                -0.036333  ...      95367.0   \n",
       "3335                -0.021180                -0.048207  ...     101933.0   \n",
       "3336                -0.000839                -0.012002  ...      83010.0   \n",
       "\n",
       "      zcr_db5_cD4  zcr_db8_cA7  zcr_db8_cD1  zcr_db8_cD2  zcr_db8_cD3  \\\n",
       "0         24515.0       1367.0     236539.0     100477.0      48721.0   \n",
       "1         21751.0       4280.0     232788.0     104560.0      40835.0   \n",
       "2         28460.0       3429.0     238953.0      98627.0      50426.0   \n",
       "3         24784.0       4084.0     239878.0     106315.0      46383.0   \n",
       "4         21473.0       3355.0     235508.0      96446.0      50054.0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3332      57071.0       5266.0     478728.0     194404.0     110085.0   \n",
       "3333      57721.0       5961.0     378640.0     180357.0      98690.0   \n",
       "3334      62597.0       3067.0     491052.0     210852.0      92628.0   \n",
       "3335      50380.0       5290.0     483699.0     219884.0     100631.0   \n",
       "3336      50099.0       2977.0     314037.0     172281.0      68302.0   \n",
       "\n",
       "      zcr_db8_cD4  zcr_db8_cD5  zcr_db8_cD6  zcr_db8_cD7  \n",
       "0         24523.0      10601.0       5868.0       2136.0  \n",
       "1         21922.0      11688.0       5678.0       4187.0  \n",
       "2         28197.0      12380.0       5750.0       2853.0  \n",
       "3         25001.0      10550.0       6405.0       3401.0  \n",
       "4         21542.0      11100.0       6028.0       3176.0  \n",
       "...           ...          ...          ...          ...  \n",
       "3332      56729.0      26120.0      10705.0       4714.0  \n",
       "3333      57296.0      25947.0      13375.0       3125.0  \n",
       "3334      61759.0      24119.0      12008.0       6321.0  \n",
       "3335      49950.0      30214.0       9810.0       5397.0  \n",
       "3336      46699.0      30988.0      13057.0       4685.0  \n",
       "\n",
       "[3337 rows x 361 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "features = pandas.read_csv(MOUNTED_DATASET_PATH + '/data/cleaned_features_1.csv', index_col=0)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25th_percentile_db4_cA4</th>\n",
       "      <th>25th_percentile_db4_cD1</th>\n",
       "      <th>25th_percentile_db4_cD2</th>\n",
       "      <th>25th_percentile_db4_cD3</th>\n",
       "      <th>25th_percentile_db4_cD4</th>\n",
       "      <th>25th_percentile_db5_cA4</th>\n",
       "      <th>25th_percentile_db5_cD1</th>\n",
       "      <th>25th_percentile_db5_cD2</th>\n",
       "      <th>25th_percentile_db5_cD3</th>\n",
       "      <th>25th_percentile_db5_cD4</th>\n",
       "      <th>...</th>\n",
       "      <th>zcr_db5_cD3</th>\n",
       "      <th>zcr_db5_cD4</th>\n",
       "      <th>zcr_db8_cA7</th>\n",
       "      <th>zcr_db8_cD1</th>\n",
       "      <th>zcr_db8_cD2</th>\n",
       "      <th>zcr_db8_cD3</th>\n",
       "      <th>zcr_db8_cD4</th>\n",
       "      <th>zcr_db8_cD5</th>\n",
       "      <th>zcr_db8_cD6</th>\n",
       "      <th>zcr_db8_cD7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>-0.458771</td>\n",
       "      <td>-0.011345</td>\n",
       "      <td>-0.040091</td>\n",
       "      <td>-0.083547</td>\n",
       "      <td>-0.169737</td>\n",
       "      <td>-0.459046</td>\n",
       "      <td>-0.010723</td>\n",
       "      <td>-0.039571</td>\n",
       "      <td>-0.081663</td>\n",
       "      <td>-0.168709</td>\n",
       "      <td>...</td>\n",
       "      <td>91014.0</td>\n",
       "      <td>52085.0</td>\n",
       "      <td>6553.0</td>\n",
       "      <td>514430.0</td>\n",
       "      <td>224480.0</td>\n",
       "      <td>91035.0</td>\n",
       "      <td>52395.0</td>\n",
       "      <td>21672.0</td>\n",
       "      <td>11281.0</td>\n",
       "      <td>6760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>-0.331145</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>-0.008179</td>\n",
       "      <td>-0.043446</td>\n",
       "      <td>-0.068350</td>\n",
       "      <td>-0.331757</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>-0.007001</td>\n",
       "      <td>-0.043348</td>\n",
       "      <td>-0.068130</td>\n",
       "      <td>...</td>\n",
       "      <td>126785.0</td>\n",
       "      <td>36192.0</td>\n",
       "      <td>6470.0</td>\n",
       "      <td>374737.0</td>\n",
       "      <td>214912.0</td>\n",
       "      <td>126898.0</td>\n",
       "      <td>36477.0</td>\n",
       "      <td>24035.0</td>\n",
       "      <td>13175.0</td>\n",
       "      <td>6777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>-0.138664</td>\n",
       "      <td>-0.001379</td>\n",
       "      <td>-0.003927</td>\n",
       "      <td>-0.010158</td>\n",
       "      <td>-0.026524</td>\n",
       "      <td>-0.137422</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>-0.003817</td>\n",
       "      <td>-0.009750</td>\n",
       "      <td>-0.025942</td>\n",
       "      <td>...</td>\n",
       "      <td>104629.0</td>\n",
       "      <td>51057.0</td>\n",
       "      <td>8128.0</td>\n",
       "      <td>486783.0</td>\n",
       "      <td>206166.0</td>\n",
       "      <td>103967.0</td>\n",
       "      <td>50431.0</td>\n",
       "      <td>25749.0</td>\n",
       "      <td>11937.0</td>\n",
       "      <td>5732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>-0.459344</td>\n",
       "      <td>-0.014304</td>\n",
       "      <td>-0.038177</td>\n",
       "      <td>-0.063067</td>\n",
       "      <td>-0.085567</td>\n",
       "      <td>-0.461462</td>\n",
       "      <td>-0.013701</td>\n",
       "      <td>-0.037880</td>\n",
       "      <td>-0.063500</td>\n",
       "      <td>-0.085462</td>\n",
       "      <td>...</td>\n",
       "      <td>94492.0</td>\n",
       "      <td>47070.0</td>\n",
       "      <td>6084.0</td>\n",
       "      <td>483397.0</td>\n",
       "      <td>191129.0</td>\n",
       "      <td>94247.0</td>\n",
       "      <td>47111.0</td>\n",
       "      <td>23785.0</td>\n",
       "      <td>12232.0</td>\n",
       "      <td>6456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>-0.871877</td>\n",
       "      <td>-0.010415</td>\n",
       "      <td>-0.035570</td>\n",
       "      <td>-0.086992</td>\n",
       "      <td>-0.230081</td>\n",
       "      <td>-0.875678</td>\n",
       "      <td>-0.009762</td>\n",
       "      <td>-0.034515</td>\n",
       "      <td>-0.083134</td>\n",
       "      <td>-0.224582</td>\n",
       "      <td>...</td>\n",
       "      <td>113379.0</td>\n",
       "      <td>48083.0</td>\n",
       "      <td>6258.0</td>\n",
       "      <td>481254.0</td>\n",
       "      <td>207868.0</td>\n",
       "      <td>113030.0</td>\n",
       "      <td>48392.0</td>\n",
       "      <td>25497.0</td>\n",
       "      <td>9858.0</td>\n",
       "      <td>6246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.507808</td>\n",
       "      <td>-0.011467</td>\n",
       "      <td>-0.025933</td>\n",
       "      <td>-0.033618</td>\n",
       "      <td>-0.065211</td>\n",
       "      <td>-0.507328</td>\n",
       "      <td>-0.011109</td>\n",
       "      <td>-0.025656</td>\n",
       "      <td>-0.033134</td>\n",
       "      <td>-0.063043</td>\n",
       "      <td>...</td>\n",
       "      <td>43896.0</td>\n",
       "      <td>25719.0</td>\n",
       "      <td>3849.0</td>\n",
       "      <td>228299.0</td>\n",
       "      <td>90473.0</td>\n",
       "      <td>43625.0</td>\n",
       "      <td>25554.0</td>\n",
       "      <td>12939.0</td>\n",
       "      <td>6879.0</td>\n",
       "      <td>2764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>-0.771594</td>\n",
       "      <td>-0.021030</td>\n",
       "      <td>-0.048028</td>\n",
       "      <td>-0.079806</td>\n",
       "      <td>-0.110843</td>\n",
       "      <td>-0.770188</td>\n",
       "      <td>-0.020619</td>\n",
       "      <td>-0.047055</td>\n",
       "      <td>-0.080227</td>\n",
       "      <td>-0.109552</td>\n",
       "      <td>...</td>\n",
       "      <td>94797.0</td>\n",
       "      <td>46537.0</td>\n",
       "      <td>3437.0</td>\n",
       "      <td>519454.0</td>\n",
       "      <td>186289.0</td>\n",
       "      <td>94732.0</td>\n",
       "      <td>46582.0</td>\n",
       "      <td>28336.0</td>\n",
       "      <td>10566.0</td>\n",
       "      <td>5509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>-0.379905</td>\n",
       "      <td>-0.002791</td>\n",
       "      <td>-0.016099</td>\n",
       "      <td>-0.041235</td>\n",
       "      <td>-0.074148</td>\n",
       "      <td>-0.380161</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-0.015578</td>\n",
       "      <td>-0.041450</td>\n",
       "      <td>-0.073217</td>\n",
       "      <td>...</td>\n",
       "      <td>90724.0</td>\n",
       "      <td>54572.0</td>\n",
       "      <td>5676.0</td>\n",
       "      <td>450466.0</td>\n",
       "      <td>244559.0</td>\n",
       "      <td>90633.0</td>\n",
       "      <td>54455.0</td>\n",
       "      <td>25111.0</td>\n",
       "      <td>10249.0</td>\n",
       "      <td>6129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>-0.172565</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>-0.002494</td>\n",
       "      <td>-0.009889</td>\n",
       "      <td>-0.172684</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.002385</td>\n",
       "      <td>-0.009207</td>\n",
       "      <td>...</td>\n",
       "      <td>109863.0</td>\n",
       "      <td>58467.0</td>\n",
       "      <td>7308.0</td>\n",
       "      <td>512640.0</td>\n",
       "      <td>194589.0</td>\n",
       "      <td>107884.0</td>\n",
       "      <td>56299.0</td>\n",
       "      <td>27247.0</td>\n",
       "      <td>15411.0</td>\n",
       "      <td>3589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>-0.576360</td>\n",
       "      <td>-0.005777</td>\n",
       "      <td>-0.025792</td>\n",
       "      <td>-0.079405</td>\n",
       "      <td>-0.165310</td>\n",
       "      <td>-0.576974</td>\n",
       "      <td>-0.005249</td>\n",
       "      <td>-0.024827</td>\n",
       "      <td>-0.079393</td>\n",
       "      <td>-0.163148</td>\n",
       "      <td>...</td>\n",
       "      <td>112454.0</td>\n",
       "      <td>47185.0</td>\n",
       "      <td>5887.0</td>\n",
       "      <td>471745.0</td>\n",
       "      <td>220437.0</td>\n",
       "      <td>111477.0</td>\n",
       "      <td>46851.0</td>\n",
       "      <td>24400.0</td>\n",
       "      <td>11808.0</td>\n",
       "      <td>5834.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3337 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      25th_percentile_db4_cA4  25th_percentile_db4_cD1  \\\n",
       "1810                -0.458771                -0.011345   \n",
       "1881                -0.331145                -0.000822   \n",
       "2694                -0.138664                -0.001379   \n",
       "1304                -0.459344                -0.014304   \n",
       "2957                -0.871877                -0.010415   \n",
       "...                       ...                      ...   \n",
       "89                  -0.507808                -0.011467   \n",
       "1541                -0.771594                -0.021030   \n",
       "2581                -0.379905                -0.002791   \n",
       "809                 -0.172565                -0.000336   \n",
       "3266                -0.576360                -0.005777   \n",
       "\n",
       "      25th_percentile_db4_cD2  25th_percentile_db4_cD3  \\\n",
       "1810                -0.040091                -0.083547   \n",
       "1881                -0.008179                -0.043446   \n",
       "2694                -0.003927                -0.010158   \n",
       "1304                -0.038177                -0.063067   \n",
       "2957                -0.035570                -0.086992   \n",
       "...                       ...                      ...   \n",
       "89                  -0.025933                -0.033618   \n",
       "1541                -0.048028                -0.079806   \n",
       "2581                -0.016099                -0.041235   \n",
       "809                 -0.001042                -0.002494   \n",
       "3266                -0.025792                -0.079405   \n",
       "\n",
       "      25th_percentile_db4_cD4  25th_percentile_db5_cA4  \\\n",
       "1810                -0.169737                -0.459046   \n",
       "1881                -0.068350                -0.331757   \n",
       "2694                -0.026524                -0.137422   \n",
       "1304                -0.085567                -0.461462   \n",
       "2957                -0.230081                -0.875678   \n",
       "...                       ...                      ...   \n",
       "89                  -0.065211                -0.507328   \n",
       "1541                -0.110843                -0.770188   \n",
       "2581                -0.074148                -0.380161   \n",
       "809                 -0.009889                -0.172684   \n",
       "3266                -0.165310                -0.576974   \n",
       "\n",
       "      25th_percentile_db5_cD1  25th_percentile_db5_cD2  \\\n",
       "1810                -0.010723                -0.039571   \n",
       "1881                -0.000596                -0.007001   \n",
       "2694                -0.001322                -0.003817   \n",
       "1304                -0.013701                -0.037880   \n",
       "2957                -0.009762                -0.034515   \n",
       "...                       ...                      ...   \n",
       "89                  -0.011109                -0.025656   \n",
       "1541                -0.020619                -0.047055   \n",
       "2581                -0.002411                -0.015578   \n",
       "809                 -0.000319                -0.001026   \n",
       "3266                -0.005249                -0.024827   \n",
       "\n",
       "      25th_percentile_db5_cD3  25th_percentile_db5_cD4  ...  zcr_db5_cD3  \\\n",
       "1810                -0.081663                -0.168709  ...      91014.0   \n",
       "1881                -0.043348                -0.068130  ...     126785.0   \n",
       "2694                -0.009750                -0.025942  ...     104629.0   \n",
       "1304                -0.063500                -0.085462  ...      94492.0   \n",
       "2957                -0.083134                -0.224582  ...     113379.0   \n",
       "...                       ...                      ...  ...          ...   \n",
       "89                  -0.033134                -0.063043  ...      43896.0   \n",
       "1541                -0.080227                -0.109552  ...      94797.0   \n",
       "2581                -0.041450                -0.073217  ...      90724.0   \n",
       "809                 -0.002385                -0.009207  ...     109863.0   \n",
       "3266                -0.079393                -0.163148  ...     112454.0   \n",
       "\n",
       "      zcr_db5_cD4  zcr_db8_cA7  zcr_db8_cD1  zcr_db8_cD2  zcr_db8_cD3  \\\n",
       "1810      52085.0       6553.0     514430.0     224480.0      91035.0   \n",
       "1881      36192.0       6470.0     374737.0     214912.0     126898.0   \n",
       "2694      51057.0       8128.0     486783.0     206166.0     103967.0   \n",
       "1304      47070.0       6084.0     483397.0     191129.0      94247.0   \n",
       "2957      48083.0       6258.0     481254.0     207868.0     113030.0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "89        25719.0       3849.0     228299.0      90473.0      43625.0   \n",
       "1541      46537.0       3437.0     519454.0     186289.0      94732.0   \n",
       "2581      54572.0       5676.0     450466.0     244559.0      90633.0   \n",
       "809       58467.0       7308.0     512640.0     194589.0     107884.0   \n",
       "3266      47185.0       5887.0     471745.0     220437.0     111477.0   \n",
       "\n",
       "      zcr_db8_cD4  zcr_db8_cD5  zcr_db8_cD6  zcr_db8_cD7  \n",
       "1810      52395.0      21672.0      11281.0       6760.0  \n",
       "1881      36477.0      24035.0      13175.0       6777.0  \n",
       "2694      50431.0      25749.0      11937.0       5732.0  \n",
       "1304      47111.0      23785.0      12232.0       6456.0  \n",
       "2957      48392.0      25497.0       9858.0       6246.0  \n",
       "...           ...          ...          ...          ...  \n",
       "89        25554.0      12939.0       6879.0       2764.0  \n",
       "1541      46582.0      28336.0      10566.0       5509.0  \n",
       "2581      54455.0      25111.0      10249.0       6129.0  \n",
       "809       56299.0      27247.0      15411.0       3589.0  \n",
       "3266      46851.0      24400.0      11808.0       5834.0  \n",
       "\n",
       "[3337 rows x 361 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle dataset\n",
    "features = features.reindex(numpy.random.permutation(features.index))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split dataset into target (y) and predictors (x)\n",
    "y = features.loc[:,'genre_label']\n",
    "X = features.loc[:, features.columns.difference(['genre_label'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictor labels\n",
    "predictors_all_label = X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2669, 360), (668, 360), (2669,), (668,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into sets: training 80% & testing 20% of total dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create normalization pipelines\n",
    "norm_pipe = normalization_pipeline(\n",
    "    predictors_all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ncols = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2669, 3), (668, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding our labels\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set log directory for tensorboard logs\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(): \n",
    "    '''\n",
    "    get_run_logdir() generates subdirectory path with\n",
    "    current date & time.\n",
    "    '''   \n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") \n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_01_16-11_28_43'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tensorbaord & early stopping callback\n",
    "tensorboard_cb = callbacks.TensorBoard(run_logdir) \n",
    "\n",
    "early_stopping_cb = callbacks.EarlyStopping(patience=10,\n",
    "                                        restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'clf__units': 2, 'clf__optimizer': 'adam',\n",
    "    'clf__n_hidden': 2, 'clf__lr': 0.0001,\n",
    "    'clf__kernel_initializer': 'glorot_uniform',\n",
    "    'clf__filters': 32, 'clf__dropout': 0.15,\n",
    "    'clf__activation': 'selu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wrap the function with keras wrapper\n",
    "clf = KerasClassifier(\n",
    "    build_fn=set_shape_create_cnn_model('cnn', ncols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('norm_pipe', norm_pipe),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipe = pipe.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 358, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 179, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 177, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 88, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 86, 96)            18528     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 43, 96)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4128)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 8258      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 9         \n",
      "=================================================================\n",
      "Total params: 33,137\n",
      "Trainable params: 33,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 2s 13ms/step - loss: 1.1012 - accuracy: 0.3597 - val_loss: 1.1005 - val_accuracy: 0.3071\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 1.0582 - accuracy: 0.4230 - val_loss: 1.0290 - val_accuracy: 0.5599\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 2s 13ms/step - loss: 1.0369 - accuracy: 0.4890 - val_loss: 1.0255 - val_accuracy: 0.6049\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 1.0182 - accuracy: 0.5208 - val_loss: 0.9903 - val_accuracy: 0.5787\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 1.0110 - accuracy: 0.5354 - val_loss: 1.0215 - val_accuracy: 0.5880\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 1.0006 - accuracy: 0.5415 - val_loss: 0.9624 - val_accuracy: 0.6067\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 2s 11ms/step - loss: 0.9837 - accuracy: 0.5527 - val_loss: 0.9535 - val_accuracy: 0.6461\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.9704 - accuracy: 0.5513 - val_loss: 0.9463 - val_accuracy: 0.6461\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.9650 - accuracy: 0.5761 - val_loss: 0.9587 - val_accuracy: 0.6573\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.9589 - accuracy: 0.5756 - val_loss: 0.9130 - val_accuracy: 0.6704\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.9477 - accuracy: 0.5827 - val_loss: 0.9064 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.9330 - accuracy: 0.5855 - val_loss: 0.8933 - val_accuracy: 0.6704\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 3s 20ms/step - loss: 0.9409 - accuracy: 0.5686 - val_loss: 0.8826 - val_accuracy: 0.6723\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 3s 20ms/step - loss: 0.9238 - accuracy: 0.5780 - val_loss: 0.8750 - val_accuracy: 0.6648\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.9135 - accuracy: 0.5869 - val_loss: 0.8625 - val_accuracy: 0.6742\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.8959 - accuracy: 0.5934 - val_loss: 0.8794 - val_accuracy: 0.6798\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.8865 - accuracy: 0.5958 - val_loss: 0.8479 - val_accuracy: 0.6891\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.8751 - accuracy: 0.6037 - val_loss: 0.8263 - val_accuracy: 0.6891\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.8754 - accuracy: 0.6009 - val_loss: 0.8431 - val_accuracy: 0.6891\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 2s 13ms/step - loss: 0.8596 - accuracy: 0.6061 - val_loss: 0.8401 - val_accuracy: 0.6835\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.8561 - accuracy: 0.6019 - val_loss: 0.8179 - val_accuracy: 0.6723\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.8424 - accuracy: 0.6066 - val_loss: 0.8033 - val_accuracy: 0.6948\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.8237 - accuracy: 0.6112 - val_loss: 0.7776 - val_accuracy: 0.7154\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.8276 - accuracy: 0.6136 - val_loss: 0.7744 - val_accuracy: 0.7135\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 2s 13ms/step - loss: 0.8108 - accuracy: 0.6145 - val_loss: 0.7702 - val_accuracy: 0.6985\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.8222 - accuracy: 0.6136 - val_loss: 0.7672 - val_accuracy: 0.7097\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.8073 - accuracy: 0.6248 - val_loss: 0.7590 - val_accuracy: 0.7154\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.7861 - accuracy: 0.6403 - val_loss: 0.7600 - val_accuracy: 0.7172\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.8080 - accuracy: 0.6084 - val_loss: 0.7800 - val_accuracy: 0.6910\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 2s 14ms/step - loss: 0.7946 - accuracy: 0.6150 - val_loss: 0.7410 - val_accuracy: 0.7266\n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 2s 13ms/step - loss: 0.7997 - accuracy: 0.6215 - val_loss: 0.7468 - val_accuracy: 0.7191\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.7894 - accuracy: 0.6206 - val_loss: 0.7495 - val_accuracy: 0.7079\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.7843 - accuracy: 0.6131 - val_loss: 0.7358 - val_accuracy: 0.7210\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.7655 - accuracy: 0.6454 - val_loss: 0.7441 - val_accuracy: 0.7060\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.7650 - accuracy: 0.6365 - val_loss: 0.7518 - val_accuracy: 0.6929\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 3s 20ms/step - loss: 0.7556 - accuracy: 0.6436 - val_loss: 0.7381 - val_accuracy: 0.7060\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 3s 21ms/step - loss: 0.7603 - accuracy: 0.6258 - val_loss: 0.7226 - val_accuracy: 0.6966\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 3s 19ms/step - loss: 0.7473 - accuracy: 0.6365 - val_loss: 0.7133 - val_accuracy: 0.7116\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 2s 13ms/step - loss: 0.7561 - accuracy: 0.6286 - val_loss: 0.7295 - val_accuracy: 0.6891\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.7508 - accuracy: 0.6365 - val_loss: 0.7397 - val_accuracy: 0.7004\n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.7303 - accuracy: 0.6468 - val_loss: 0.7042 - val_accuracy: 0.7154\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.7298 - accuracy: 0.6365 - val_loss: 0.7074 - val_accuracy: 0.7041\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 2s 14ms/step - loss: 0.7195 - accuracy: 0.6571 - val_loss: 0.7049 - val_accuracy: 0.7135\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 2s 12ms/step - loss: 0.7056 - accuracy: 0.6464 - val_loss: 0.7065 - val_accuracy: 0.7097\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.7231 - accuracy: 0.6454 - val_loss: 0.6957 - val_accuracy: 0.7097\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.7108 - accuracy: 0.6496 - val_loss: 0.6932 - val_accuracy: 0.7228\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.7034 - accuracy: 0.6515 - val_loss: 0.6937 - val_accuracy: 0.7266\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.7039 - accuracy: 0.6440 - val_loss: 0.6877 - val_accuracy: 0.7285\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 2s 11ms/step - loss: 0.6834 - accuracy: 0.6703 - val_loss: 0.6858 - val_accuracy: 0.7154\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.6744 - accuracy: 0.6806 - val_loss: 0.6932 - val_accuracy: 0.7004\n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.6786 - accuracy: 0.6726 - val_loss: 0.6807 - val_accuracy: 0.7191\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.6725 - accuracy: 0.6703 - val_loss: 0.6833 - val_accuracy: 0.7322\n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.6868 - accuracy: 0.6590 - val_loss: 0.6740 - val_accuracy: 0.7453\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.6853 - accuracy: 0.6642 - val_loss: 0.6736 - val_accuracy: 0.7285\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.6876 - accuracy: 0.6590 - val_loss: 0.6772 - val_accuracy: 0.7154\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.6690 - accuracy: 0.6763 - val_loss: 0.6852 - val_accuracy: 0.7172\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 3s 18ms/step - loss: 0.6694 - accuracy: 0.6637 - val_loss: 0.6986 - val_accuracy: 0.7097\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 2s 14ms/step - loss: 0.6610 - accuracy: 0.6773 - val_loss: 0.6733 - val_accuracy: 0.7172\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.6582 - accuracy: 0.6782 - val_loss: 0.6650 - val_accuracy: 0.7378\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 3s 21ms/step - loss: 0.6668 - accuracy: 0.6782 - val_loss: 0.6650 - val_accuracy: 0.7247\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 3s 21ms/step - loss: 0.6468 - accuracy: 0.6740 - val_loss: 0.6694 - val_accuracy: 0.7322\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.6478 - accuracy: 0.6904 - val_loss: 0.6697 - val_accuracy: 0.7434\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 2s 13ms/step - loss: 0.6349 - accuracy: 0.6979 - val_loss: 0.6731 - val_accuracy: 0.7285\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.6247 - accuracy: 0.7035 - val_loss: 0.6668 - val_accuracy: 0.7135\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.6330 - accuracy: 0.6993 - val_loss: 0.6651 - val_accuracy: 0.7210\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.6258 - accuracy: 0.6909 - val_loss: 0.6587 - val_accuracy: 0.7434\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.6175 - accuracy: 0.6979 - val_loss: 0.6743 - val_accuracy: 0.7228\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 2s 13ms/step - loss: 0.6217 - accuracy: 0.6927 - val_loss: 0.6622 - val_accuracy: 0.7191\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.6243 - accuracy: 0.6876 - val_loss: 0.6622 - val_accuracy: 0.7210\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.6148 - accuracy: 0.6946 - val_loss: 0.6550 - val_accuracy: 0.7266\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 2s 14ms/step - loss: 0.6128 - accuracy: 0.7026 - val_loss: 0.6585 - val_accuracy: 0.7228\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.6123 - accuracy: 0.6960 - val_loss: 0.6843 - val_accuracy: 0.6985\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 2s 14ms/step - loss: 0.6145 - accuracy: 0.6974 - val_loss: 0.6612 - val_accuracy: 0.7154\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.6066 - accuracy: 0.7105 - val_loss: 0.6830 - val_accuracy: 0.6854\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.5988 - accuracy: 0.7007 - val_loss: 0.6578 - val_accuracy: 0.7228\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 2s 14ms/step - loss: 0.6028 - accuracy: 0.6946 - val_loss: 0.6559 - val_accuracy: 0.7247\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 2s 13ms/step - loss: 0.5971 - accuracy: 0.7087 - val_loss: 0.6593 - val_accuracy: 0.7322\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.5853 - accuracy: 0.7101 - val_loss: 0.6621 - val_accuracy: 0.7210\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.6026 - accuracy: 0.6960 - val_loss: 0.6524 - val_accuracy: 0.7303\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.5833 - accuracy: 0.7148 - val_loss: 0.6555 - val_accuracy: 0.7247\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 2s 14ms/step - loss: 0.5727 - accuracy: 0.7068 - val_loss: 0.6795 - val_accuracy: 0.6891\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 2s 11ms/step - loss: 0.5990 - accuracy: 0.7040 - val_loss: 0.6619 - val_accuracy: 0.7022\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.5487 - accuracy: 0.7279 - val_loss: 0.6416 - val_accuracy: 0.7509\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 3s 21ms/step - loss: 0.5759 - accuracy: 0.7222 - val_loss: 0.6442 - val_accuracy: 0.7360\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 3s 21ms/step - loss: 0.5642 - accuracy: 0.7279 - val_loss: 0.6581 - val_accuracy: 0.7154\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.5554 - accuracy: 0.7260 - val_loss: 0.6554 - val_accuracy: 0.7266\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 2s 16ms/step - loss: 0.5633 - accuracy: 0.7077 - val_loss: 0.6582 - val_accuracy: 0.7116\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.5660 - accuracy: 0.7148 - val_loss: 0.6592 - val_accuracy: 0.7116\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 2s 17ms/step - loss: 0.5583 - accuracy: 0.7176 - val_loss: 0.6508 - val_accuracy: 0.7360\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.5536 - accuracy: 0.7194 - val_loss: 0.6489 - val_accuracy: 0.7341\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 2s 12ms/step - loss: 0.5543 - accuracy: 0.7288 - val_loss: 0.6603 - val_accuracy: 0.7397\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.5497 - accuracy: 0.7213 - val_loss: 0.6500 - val_accuracy: 0.7397\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.5342 - accuracy: 0.7513 - val_loss: 0.6587 - val_accuracy: 0.7191\n"
     ]
    }
   ],
   "source": [
    "# training best classifier with all training set & validate with test set\n",
    "pipe = pipe.fit(X_train, y_train, clf__batch_size=15,\n",
    "                clf__validation_split=0.2, clf__epochs=100,\n",
    "                clf__callbacks=[tensorboard_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/macbookretina/Desktop/automatic-music-genre-classification/venv/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:264: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n"
     ]
    }
   ],
   "source": [
    "predicted_y_test = pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09660336, 0.31013337, 0.5932632 ],\n",
       "       [0.7999834 , 0.07174283, 0.12827373],\n",
       "       [0.3129914 , 0.3231803 , 0.3638283 ],\n",
       "       ...,\n",
       "       [0.9604021 , 0.00411725, 0.03548069],\n",
       "       [0.92532307, 0.01620113, 0.05847583],\n",
       "       [0.00353163, 0.9943474 , 0.00212092]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - hiphop: 219\n",
      "1 - rock: 232\n",
      "2 - pop: 217\n"
     ]
    }
   ],
   "source": [
    "# check the number of targets per class\n",
    "for i in range(3):\n",
    "    print(str(i) + ' - ' +  GENRES[i] + ': ' +\n",
    "          str(sum([1 for target in y_test if target[i] == 1])))\n",
    "#     print(f'{i}: {sum([1 for target in y_test if target[i] == 1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - hiphop: 234\n",
      "1 - rock: 227\n",
      "2 - pop: 207\n"
     ]
    }
   ],
   "source": [
    "# check the number of predicted values in each class\n",
    "for i in range(3): \n",
    "    print(str(i) + ' - ' +  GENRES[i] + ': ' + \n",
    "          str(sum([1 for prediction in predicted_y_test if numpy.argmax(prediction) == i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[196,   9,  14],\n",
       "       [ 11, 168,  53],\n",
       "       [ 27,  50, 140]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the confusion matrix \n",
    "# row: actual\n",
    "# columns: predicted\n",
    "conf_matrix = confusion_matrix(numpy.argmax(y_test, 1), numpy.argmax(predicted_y_test, 1))\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>168</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  196    9   14\n",
       "1   11  168   53\n",
       "2   27   50  140"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of the confusion matrix with genre labels for readability \n",
    "confusion_df = pandas.DataFrame(conf_matrix)\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRES_MAP = {\n",
    "    0: 'hiphop',\n",
    "    1: 'rock',\n",
    "    2: 'pop'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hiphop</th>\n",
       "      <th>rock</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hiphop</th>\n",
       "      <td>196</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rock</th>\n",
       "      <td>11</td>\n",
       "      <td>168</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop</th>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hiphop  rock  pop\n",
       "hiphop     196     9   14\n",
       "rock        11   168   53\n",
       "pop         27    50  140"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename rows and columns with genre labels\n",
    "confusion_df = confusion_df.rename(columns=GENRES_MAP)\n",
    "confusion_df.index = confusion_df.columns\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a heatmap for the confusion matrix for display\n",
    "pyplot.figure(figsize= (20,12))\n",
    "seaborn.set(font_scale = 2);\n",
    "ax = seaborn.heatmap(confusion_df, annot=True, cmap=seaborn.cubehelix_palette(50));\n",
    "ax.set(xlabel='Predicted Values', ylabel='Actual Values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(X, y):\n",
    "    clf = KerasClassifier(\n",
    "        build_fn=set_shape_create_cnn_model('cnn', ncols)\n",
    "    )\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('norm_pipe', norm_pipe),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "    \n",
    "    y = to_categorical(y, 3)\n",
    "    \n",
    "    return pipe.fit(X, y, clf__batch_size=15,\n",
    "                    clf__epochs=100, \n",
    "                    clf__validation_split=.2,\n",
    "                    clf__callbacks=[\n",
    "                        tensorboard_cb, \n",
    "                        early_stopping_cb\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 358, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 179, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 177, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 88, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 86, 96)            18528     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 43, 96)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4128)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8258      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 9         \n",
      "=================================================================\n",
      "Total params: 33,137\n",
      "Trainable params: 33,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 1.0901 - accuracy: 0.3795 - val_loss: 1.0646 - val_accuracy: 0.3593\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 1.0521 - accuracy: 0.4481 - val_loss: 1.0371 - val_accuracy: 0.4880\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 1.0263 - accuracy: 0.5081 - val_loss: 1.0223 - val_accuracy: 0.5374\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - 4s 22ms/step - loss: 1.0063 - accuracy: 0.5422 - val_loss: 0.9897 - val_accuracy: 0.6677\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.9960 - accuracy: 0.5478 - val_loss: 0.9702 - val_accuracy: 0.6826\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - 4s 22ms/step - loss: 0.9815 - accuracy: 0.5530 - val_loss: 0.9783 - val_accuracy: 0.5838\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 0.9769 - accuracy: 0.5590 - val_loss: 0.9378 - val_accuracy: 0.6362\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.9506 - accuracy: 0.5916 - val_loss: 0.9216 - val_accuracy: 0.6542\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - 3s 18ms/step - loss: 0.9474 - accuracy: 0.5721 - val_loss: 0.9227 - val_accuracy: 0.6991\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 0.9291 - accuracy: 0.5837 - val_loss: 0.8898 - val_accuracy: 0.6766\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.9198 - accuracy: 0.5792 - val_loss: 0.8716 - val_accuracy: 0.6826\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - 3s 18ms/step - loss: 0.9193 - accuracy: 0.5762 - val_loss: 0.8665 - val_accuracy: 0.6647\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 0.8944 - accuracy: 0.6025 - val_loss: 0.8441 - val_accuracy: 0.7141\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.8879 - accuracy: 0.5860 - val_loss: 0.8243 - val_accuracy: 0.7171\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.8879 - accuracy: 0.5954 - val_loss: 0.8179 - val_accuracy: 0.7231\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.8812 - accuracy: 0.5916 - val_loss: 0.8044 - val_accuracy: 0.7231\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - 2s 14ms/step - loss: 0.8608 - accuracy: 0.6077 - val_loss: 0.7895 - val_accuracy: 0.7141\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - 2s 13ms/step - loss: 0.8521 - accuracy: 0.6047 - val_loss: 0.7736 - val_accuracy: 0.7260\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - 3s 18ms/step - loss: 0.8498 - accuracy: 0.6028 - val_loss: 0.7814 - val_accuracy: 0.7216\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.8285 - accuracy: 0.6167 - val_loss: 0.7517 - val_accuracy: 0.7290\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 0.8196 - accuracy: 0.6253 - val_loss: 0.7579 - val_accuracy: 0.7231\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 0.8088 - accuracy: 0.6190 - val_loss: 0.7545 - val_accuracy: 0.6931\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - 3s 18ms/step - loss: 0.8120 - accuracy: 0.6208 - val_loss: 0.7213 - val_accuracy: 0.7350\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.8112 - accuracy: 0.6025 - val_loss: 0.7172 - val_accuracy: 0.7440\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.8034 - accuracy: 0.6257 - val_loss: 0.7162 - val_accuracy: 0.7320\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.7858 - accuracy: 0.6283 - val_loss: 0.7041 - val_accuracy: 0.7395\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.7922 - accuracy: 0.6167 - val_loss: 0.7014 - val_accuracy: 0.7380\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - 2s 12ms/step - loss: 0.7779 - accuracy: 0.6339 - val_loss: 0.6941 - val_accuracy: 0.7335\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.7823 - accuracy: 0.6294 - val_loss: 0.7179 - val_accuracy: 0.7126\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - 3s 18ms/step - loss: 0.7650 - accuracy: 0.6324 - val_loss: 0.6833 - val_accuracy: 0.7470\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.7534 - accuracy: 0.6418 - val_loss: 0.6730 - val_accuracy: 0.7440\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - 2s 13ms/step - loss: 0.7683 - accuracy: 0.6276 - val_loss: 0.6767 - val_accuracy: 0.7530\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - 3s 18ms/step - loss: 0.7586 - accuracy: 0.6272 - val_loss: 0.6805 - val_accuracy: 0.7440\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - 3s 18ms/step - loss: 0.7500 - accuracy: 0.6339 - val_loss: 0.6652 - val_accuracy: 0.7575\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.7361 - accuracy: 0.6411 - val_loss: 0.6594 - val_accuracy: 0.7515\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.7312 - accuracy: 0.6437 - val_loss: 0.6737 - val_accuracy: 0.7365\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.7342 - accuracy: 0.6486 - val_loss: 0.6533 - val_accuracy: 0.7515\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 0.7174 - accuracy: 0.6489 - val_loss: 0.6504 - val_accuracy: 0.7470\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - 4s 23ms/step - loss: 0.7026 - accuracy: 0.6677 - val_loss: 0.6609 - val_accuracy: 0.7530\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 0.7206 - accuracy: 0.6527 - val_loss: 0.6489 - val_accuracy: 0.7650\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 0.7146 - accuracy: 0.6632 - val_loss: 0.6453 - val_accuracy: 0.7440\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - 2s 14ms/step - loss: 0.7283 - accuracy: 0.6399 - val_loss: 0.6434 - val_accuracy: 0.7575\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.6973 - accuracy: 0.6692 - val_loss: 0.6340 - val_accuracy: 0.7650\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6963 - accuracy: 0.6553 - val_loss: 0.6349 - val_accuracy: 0.7665\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - 2s 14ms/step - loss: 0.6921 - accuracy: 0.6628 - val_loss: 0.6272 - val_accuracy: 0.7545\n",
      "Epoch 46/100\n",
      "178/178 [==============================] - 2s 12ms/step - loss: 0.7021 - accuracy: 0.6579 - val_loss: 0.6292 - val_accuracy: 0.7605\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.6911 - accuracy: 0.6594 - val_loss: 0.6326 - val_accuracy: 0.7485\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6898 - accuracy: 0.6695 - val_loss: 0.6355 - val_accuracy: 0.7440\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - 2s 14ms/step - loss: 0.6792 - accuracy: 0.6647 - val_loss: 0.6385 - val_accuracy: 0.7545\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - 2s 12ms/step - loss: 0.6680 - accuracy: 0.6767 - val_loss: 0.6330 - val_accuracy: 0.7335\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.6809 - accuracy: 0.6650 - val_loss: 0.6199 - val_accuracy: 0.7740\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.6614 - accuracy: 0.6650 - val_loss: 0.6197 - val_accuracy: 0.7605\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - 3s 14ms/step - loss: 0.6695 - accuracy: 0.6752 - val_loss: 0.6288 - val_accuracy: 0.7590\n",
      "Epoch 54/100\n",
      "178/178 [==============================] - 2s 12ms/step - loss: 0.6727 - accuracy: 0.6707 - val_loss: 0.6191 - val_accuracy: 0.7590\n",
      "Epoch 55/100\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.6580 - accuracy: 0.6853 - val_loss: 0.6143 - val_accuracy: 0.7665\n",
      "Epoch 56/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6557 - accuracy: 0.6770 - val_loss: 0.6168 - val_accuracy: 0.7590\n",
      "Epoch 57/100\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 0.6723 - accuracy: 0.6725 - val_loss: 0.6197 - val_accuracy: 0.7515\n",
      "Epoch 58/100\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 0.6486 - accuracy: 0.6740 - val_loss: 0.6263 - val_accuracy: 0.7545\n",
      "Epoch 59/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6451 - accuracy: 0.6842 - val_loss: 0.6499 - val_accuracy: 0.7275\n",
      "Epoch 60/100\n",
      "178/178 [==============================] - 3s 14ms/step - loss: 0.6369 - accuracy: 0.6905 - val_loss: 0.6098 - val_accuracy: 0.7665\n",
      "Epoch 61/100\n",
      "178/178 [==============================] - 2s 11ms/step - loss: 0.6378 - accuracy: 0.6905 - val_loss: 0.6209 - val_accuracy: 0.7590\n",
      "Epoch 62/100\n",
      "178/178 [==============================] - 3s 14ms/step - loss: 0.6471 - accuracy: 0.6797 - val_loss: 0.6194 - val_accuracy: 0.7395\n",
      "Epoch 63/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6356 - accuracy: 0.6819 - val_loss: 0.6206 - val_accuracy: 0.7575\n",
      "Epoch 64/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6286 - accuracy: 0.6969 - val_loss: 0.6040 - val_accuracy: 0.7635\n",
      "Epoch 65/100\n",
      "178/178 [==============================] - 2s 11ms/step - loss: 0.6163 - accuracy: 0.7003 - val_loss: 0.6057 - val_accuracy: 0.7635\n",
      "Epoch 66/100\n",
      "178/178 [==============================] - 3s 14ms/step - loss: 0.6353 - accuracy: 0.6875 - val_loss: 0.6024 - val_accuracy: 0.7665\n",
      "Epoch 67/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6105 - accuracy: 0.6935 - val_loss: 0.6183 - val_accuracy: 0.7605\n",
      "Epoch 68/100\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.6212 - accuracy: 0.6991 - val_loss: 0.6084 - val_accuracy: 0.7650\n",
      "Epoch 69/100\n",
      "178/178 [==============================] - 2s 11ms/step - loss: 0.5990 - accuracy: 0.7093 - val_loss: 0.6226 - val_accuracy: 0.7395\n",
      "Epoch 70/100\n",
      "178/178 [==============================] - 2s 13ms/step - loss: 0.6182 - accuracy: 0.7006 - val_loss: 0.6006 - val_accuracy: 0.7605\n",
      "Epoch 71/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6087 - accuracy: 0.7036 - val_loss: 0.6139 - val_accuracy: 0.7575\n",
      "Epoch 72/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6013 - accuracy: 0.6965 - val_loss: 0.6024 - val_accuracy: 0.7620\n",
      "Epoch 73/100\n",
      "178/178 [==============================] - 2s 11ms/step - loss: 0.6025 - accuracy: 0.7055 - val_loss: 0.5968 - val_accuracy: 0.7605\n",
      "Epoch 74/100\n",
      "178/178 [==============================] - 2s 12ms/step - loss: 0.5974 - accuracy: 0.7014 - val_loss: 0.6025 - val_accuracy: 0.7530\n",
      "Epoch 75/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.5807 - accuracy: 0.7130 - val_loss: 0.6077 - val_accuracy: 0.7605\n",
      "Epoch 76/100\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 0.6021 - accuracy: 0.7051 - val_loss: 0.6060 - val_accuracy: 0.7560\n",
      "Epoch 77/100\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 0.6014 - accuracy: 0.7033 - val_loss: 0.6044 - val_accuracy: 0.7635\n",
      "Epoch 78/100\n",
      "178/178 [==============================] - 3s 14ms/step - loss: 0.5944 - accuracy: 0.7111 - val_loss: 0.5980 - val_accuracy: 0.7665\n",
      "Epoch 79/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.5922 - accuracy: 0.7115 - val_loss: 0.6089 - val_accuracy: 0.7650\n",
      "Epoch 80/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.5615 - accuracy: 0.7280 - val_loss: 0.6078 - val_accuracy: 0.7620\n",
      "Epoch 81/100\n",
      "178/178 [==============================] - 2s 12ms/step - loss: 0.5926 - accuracy: 0.7093 - val_loss: 0.6047 - val_accuracy: 0.7590\n",
      "Epoch 82/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.5665 - accuracy: 0.7197 - val_loss: 0.5968 - val_accuracy: 0.7515\n",
      "Epoch 83/100\n",
      "178/178 [==============================] - 3s 17ms/step - loss: 0.5632 - accuracy: 0.7231 - val_loss: 0.5906 - val_accuracy: 0.7590\n",
      "Epoch 84/100\n",
      "178/178 [==============================] - 3s 14ms/step - loss: 0.5439 - accuracy: 0.7392 - val_loss: 0.6153 - val_accuracy: 0.7455\n",
      "Epoch 85/100\n",
      "178/178 [==============================] - 2s 11ms/step - loss: 0.5589 - accuracy: 0.7182 - val_loss: 0.5990 - val_accuracy: 0.7590\n",
      "Epoch 86/100\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.5542 - accuracy: 0.7186 - val_loss: 0.5914 - val_accuracy: 0.7635\n",
      "Epoch 87/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.5530 - accuracy: 0.7306 - val_loss: 0.5991 - val_accuracy: 0.7680\n",
      "Epoch 88/100\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.5628 - accuracy: 0.7138 - val_loss: 0.5949 - val_accuracy: 0.7560\n",
      "Epoch 89/100\n",
      "178/178 [==============================] - 2s 12ms/step - loss: 0.5537 - accuracy: 0.7216 - val_loss: 0.6165 - val_accuracy: 0.7620\n",
      "Epoch 90/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.5488 - accuracy: 0.7224 - val_loss: 0.5948 - val_accuracy: 0.7635\n",
      "Epoch 91/100\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.5412 - accuracy: 0.7295 - val_loss: 0.6049 - val_accuracy: 0.7590\n",
      "Epoch 92/100\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.5378 - accuracy: 0.7340 - val_loss: 0.6284 - val_accuracy: 0.7470\n",
      "Epoch 93/100\n",
      "178/178 [==============================] - 2s 12ms/step - loss: 0.5340 - accuracy: 0.7216 - val_loss: 0.6747 - val_accuracy: 0.7171\n"
     ]
    }
   ],
   "source": [
    "final_model = train_final_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pipe = final_model.named_steps['norm_pipe']\n",
    "clf = final_model.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pipeline estimator to disk\n",
    "norm_pipe_path = MOUNTED_DATASET_PATH + '/model/pipeline_estimator_1.pkl'\n",
    "joblib.dump(norm_pipe, open(norm_pipe_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save keras model to disk\n",
    "model_path = MOUNTED_DATASET_PATH + '/model/cnn_model_1.h5'\n",
    "clf.model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
